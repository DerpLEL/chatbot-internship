{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb122fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains import LLMChain, APIChain\n",
    "from langchain.chains.api.prompt import API_RESPONSE_PROMPT\n",
    "from langchain.schema import Document\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import ZeroShotAgent, AgentExecutor, AgentType, initialize_agent, Tool, load_tools\n",
    "from langchain.agents.agent_toolkits.openapi import planner\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.api import open_meteo_docs\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_endpoint = 'https://search-service01.search.windows.net'\n",
    "search_key = '73Swa5YqUR5IRMwUIqOH6ww2YBm3SveLv7rDmZVXtIAzSeBjEQe9'\n",
    "private_index_name = \"nois-private-v3-index\"\n",
    "\n",
    "retriever_private = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=private_index_name,\n",
    "    credential=AzureKeyCredential(search_key),\n",
    "    b=0.0,\n",
    "    k1=0.3,\n",
    "    searchMode=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac8b195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1171\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "def count_tokens(s):\n",
    "    return len(enc.encode(s))\n",
    "string = '''[{'id': '262aa143-307a-4b9f-848d-1e6bf2e5cacb', 'name': 'Hung Bui', 'email': 'hung.bui@nois.vn', 'fullName': 'BÙI TUẤN HƯNG', 'jobTitle': 'Lập trình viên', 'mobilePhone': '0966772170', 'birthday': '1997-08-17T00:00:00', 'offDay': 0.5, 'yearOffDay': 6, 'maxDayOff': 15, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 1, 'gender': 1, 'personalEmail': 'hungbt.dev@gmail.com', 'avatar': 'https://noishrm.blob.core.windows.net/avatar/8fec9283-e82f-43ec-8f61-addb732dabcb.jpeg', 'acceptOfferDate': '2022-10-31T00:00:00', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': 'Development Unit 1', 'groupUserId': '', 'groupUserName': 'Nhân viên chính thức', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '2021-08-10T00:00:00', 'issuedBy': 'Cục trưởng CCS QLHC về TTXH', 'placeOfTemporaryResidence': '502/15/2 Thống Nhất, p.16, Gò Vấp, TP.HCM', 'placeOfResidence': '161 Đường 458, Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM', 'relativeName': 'Lê Thị Kiều', 'relationship': 'Mẹ', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': 'Vietcombank', 'bankBranch': 'DONG SAI GON-PGD THANH DA', 'bankAccountNumber': '0531002579897', 'birthPlace': 'Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '8460719408', 'education': '', 'jobId': '', 'jobName': 'Developer', 'levelId': '', 'levelName': ''}, {'id': '72fb1693-9cc1-4923-b0a4-afb18469613c', 'name': 'KHASNH BUIF', 'email': '', 'fullName': '', 'jobTitle': '', 'mobilePhone': '', 'birthday': '', 'offDay': 1, 'yearOffDay': 0, 'maxDayOff': 0, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 0, 'gender': 0, 'personalEmail': '', 'avatar': '', 'acceptOfferDate': '', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': '', 'groupUserId': '', 'groupUserName': '', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '', 'issuedBy': '', 'placeOfTemporaryResidence': '', 'placeOfResidence': '', 'relativeName': '', 'relationship': '', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': '', 'bankBranch': '', 'bankAccountNumber': '', 'birthPlace': '', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '', 'education': '', 'jobId': '', 'jobName': '', 'levelId': '', 'levelName': ''}, {'id': 'c8604118-7db6-4e08-8926-5bd8c81bce81', 'name': 'Bao Ho', 'email': 'honguyenngocbao@gmail.com', 'fullName': 'HỒ NGUYỄN NGỌC BẢO', 'jobTitle': '', 'mobilePhone': '', 'birthday': '', 'offDay': 0, 'yearOffDay': 0, 'maxDayOff': 0, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 0, 'gender': 0, 'personalEmail': '', 'avatar': '', 'acceptOfferDate': '', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': '', 'groupUserId': '', 'groupUserName': '', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '', 'issuedBy': '', 'placeOfTemporaryResidence': '', 'placeOfResidence': '', 'relativeName': '', 'relationship': '', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': '', 'bankBranch': '', 'bankAccountNumber': '', 'birthPlace': '', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '', 'education': '', 'jobId': '', 'jobName': '', 'levelId': '', 'levelName': ''}]'''\n",
    "\n",
    "print(count_tokens(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dde3db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n",
      "WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']} verbose=False callbacks=None callback_manager=None client=<class 'openai.api_resources.chat_completion.ChatCompletion'> model_name='gpt-3.5-turbo' temperature=0.0 model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']} openai_api_key='400568d9a16740b88aff437480544a39' openai_api_base='https://openai-nois-intern.openai.azure.com/' openai_organization='' openai_proxy='' request_timeout=None max_retries=6 streaming=False n=1 max_tokens=600 deployment_name='gpt-35-turbo' openai_api_type='azure' openai_api_version='2023-03-15-preview'\n",
      "761\n"
     ]
    }
   ],
   "source": [
    "# Load up your LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0.5,\n",
    "    max_tokens=450\n",
    ")\n",
    "\n",
    "llm2 = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0,\n",
    "    max_tokens=600,\n",
    "    stop=['\\n', '<|im_end|>', '<|im_sep|>']\n",
    ")\n",
    "\n",
    "llm3 = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0.2,\n",
    "    max_tokens=600,\n",
    "    top_p=1.0\n",
    ")\n",
    "\n",
    "history = []\n",
    "history_entry = 1\n",
    "\n",
    "def get_history_as_txt():\n",
    "    txt = \"\"\n",
    "    hist = history[::-1]\n",
    "    \n",
    "    for i in hist[:3]:\n",
    "        txt += f\"\\n<|im_start|>user\\n{i['user']}\\n<|im_end|>\\n\"\n",
    "        txt += f\"<|im_start|>assistant\\n{i['AI']}\\n<|im_end|>\"\n",
    "        \n",
    "    return txt\n",
    "\n",
    "def add_to_history(user_msg, ai_msg):\n",
    "    history.append({'user': user_msg, 'AI': ai_msg})\n",
    "    \n",
    "def save_history_to_file():\n",
    "    global history_entry\n",
    "    file = open(f\"chatbot-cases/chat-{history_entry}.txt\", 'w', encoding='utf-8')\n",
    "    file.write(get_history_as_txt())\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    history_entry += 1\n",
    "    \n",
    "def doc_to_str(doc):\n",
    "    string = \"\"\n",
    "    for i in doc:\n",
    "        string += i.page_content\n",
    "        \n",
    "    return string\n",
    "\n",
    "print(llm2)\n",
    "doc = open_meteo_docs.OPEN_METEO_DOCS\n",
    "print(llm2.get_num_tokens(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440dbba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE URL: https://hrm-nois-fake.azurewebsites.net/\n",
      "\n",
      "HRM system\n",
      "API DOCUMENTATION\n",
      "Endpoints:\n",
      "- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\n",
      "- /api/User/me/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\n",
      "- /api/User/me/<email>: accepts an EMAIL string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\n",
      "- /api/User/manager-users: Use GET with this endpoint to get name of a manager user.\n",
      "- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\n",
      "\n",
      "API token length: 186\n"
     ]
    }
   ],
   "source": [
    "# print(open_meteo_docs.OPEN_METEO_DOCS)\n",
    "hrm_doc = open(\"HRM_API_DOC.txt\", 'r', encoding='utf-8')\n",
    "api_doc = hrm_doc.read()\n",
    "print(api_doc)\n",
    "print(f\"API token length: {count_tokens(api_doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b02489",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_new = APIChain.from_llm_and_api_docs(llm2, api_doc, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e00702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lc_kwargs={'api_request_chain': LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text'), 'api_answer_chain': LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text'), 'requests_wrapper': TextRequestsWrapper(headers=None, aiosession=None), 'api_docs': \"BASE URL: https://hrm-nois-fake.azurewebsites.net/\\n\\nHRM system\\nAPI DOCUMENTATION\\nEndpoints:\\n- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\\n- /api/User/me/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/me/<email>: accepts an EMAIL string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/manager-users: Use GET with this endpoint to get name of a manager user.\\n- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\\n\", 'verbose': True} memory=None callbacks=None callback_manager=None verbose=True api_request_chain=LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text') api_answer_chain=LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text') requests_wrapper=TextRequestsWrapper(headers=None, aiosession=None) api_docs=\"BASE URL: https://hrm-nois-fake.azurewebsites.net/\\n\\nHRM system\\nAPI DOCUMENTATION\\nEndpoints:\\n- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\\n- /api/User/me/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/me/<email>: accepts an EMAIL string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/manager-users: Use GET with this endpoint to get name of a manager user.\\n- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\\n\" question_key='question' output_key='output'\n"
     ]
    }
   ],
   "source": [
    "print(chain_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2962f4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mhttps://hrm-nois-fake.azurewebsites.net/api/User\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{\"message\":\"OK\",\"data\":[{\"id\":\"262aa143-307a-4b9f-848d-1e6bf2e5cacb\",\"name\":\"Hung Bui\",\"email\":\"hung.bui@nois.vn\",\"fullName\":\"BÙI TUẤN HƯNG\",\"jobTitle\":\"Lập trình viên\",\"mobilePhone\":\"0966772170\",\"birthday\":\"1997-08-17T00:00:00\",\"offDay\":0.5,\"yearOffDay\":6,\"maxDayOff\":15,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":1,\"gender\":1,\"personalEmail\":\"hungbt.dev@gmail.com\",\"avatar\":\"https://noishrm.blob.core.windows.net/avatar/8fec9283-e82f-43ec-8f61-addb732dabcb.jpeg\",\"acceptOfferDate\":\"2022-10-31T00:00:00\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"Development Unit 1\",\"groupUserId\":\"\",\"groupUserName\":\"Nhân viên chính thức\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"2021-08-10T00:00:00\",\"issuedBy\":\"Cục trưởng CCS QLHC về TTXH\",\"placeOfTemporaryResidence\":\"502/15/2 Thống Nhất, p.16, Gò Vấp, TP.HCM\",\"placeOfResidence\":\"161 Đường 458, Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM\",\"relativeName\":\"Lê Thị Kiều\",\"relationship\":\"Mẹ\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"Vietcombank\",\"bankBranch\":\"DONG SAI GON-PGD THANH DA\",\"bankAccountNumber\":\"0531002579897\",\"birthPlace\":\"Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"8460719408\",\"education\":\"\",\"jobId\":\"\",\"jobName\":\"Developer\",\"levelId\":\"\",\"levelName\":\"\"},{\"id\":\"65255df1-d4c3-479b-a4b8-d63cb3db2beb\",\"name\":\"Nghiem Vo\",\"email\":\"nghiem.vo@nois.vn\",\"fullName\":\"VÕ NGỌC DUY NGHIÊM\",\"jobTitle\":\"Lập trình viên\",\"mobilePhone\":\"0843961713\",\"birthday\":\"1999\",\"offDay\":1,\"yearOffDay\":0,\"maxDayOff\":10,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":0,\"gender\":0,\"personalEmail\":\"\",\"avatar\":\"\",\"acceptOfferDate\":\"\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"Development Unit 1\",\"groupUserId\":\"\",\"groupUserName\":\"\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"\",\"issuedBy\":\"\",\"placeOfTemporaryResidence\":\"\",\"placeOfResidence\":\"\",\"relativeName\":\"\",\"relationship\":\"\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"VIB\",\"bankBranch\":\"\",\"bankAccountNumber\":\"863644436\",\"birthPlace\":\"Los Angeles\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"\",\"education\":\"Bach Khoa University\",\"jobId\":\"\",\"jobName\":\"chatbot\",\"levelId\":\"\",\"levelName\":\"Internship\"},{\"id\":\"c8604118-7db6-4e08-8926-5bd8c81bce81\",\"name\":\"Bao Ho\",\"email\":\"honguyenngocbao@gmail.com\",\"fullName\":\"HỒ NGUYỄN NGỌC BẢO\",\"jobTitle\":\"\",\"mobilePhone\":\"\",\"birthday\":\"\",\"offDay\":1.5,\"yearOffDay\":0,\"maxDayOff\":0,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":0,\"gender\":0,\"personalEmail\":\"\",\"avatar\":\"\",\"acceptOfferDate\":\"\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"\",\"groupUserId\":\"\",\"groupUserName\":\"\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"\",\"issuedBy\":\"\",\"placeOfTemporaryResidence\":\"\",\"placeOfResidence\":\"\",\"relativeName\":\"\",\"relationship\":\"\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"\",\"bankBranch\":\"\",\"bankAccountNumber\":\"\",\"birthPlace\":\"\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"\",\"education\":\"\",\"jobId\":\"\",\"jobName\":\"\",\"levelId\":\"\",\"levelName\":\"\"}]}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"Users's birthday'?\",\n",
       " 'output': \"The response contains a list of users within the HRM system. Each user has various details, including their ID, name, email, job title, mobile phone, birthday, and other personal information. However, the specific user's birthday is not provided in the response.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new(\"Users's birthday'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "78b1d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-11\n"
     ]
    }
   ],
   "source": [
    "url = \"https://hrm-nois-fake.azurewebsites.net/\"\n",
    "date = str(datetime.now().date())\n",
    "email = 'nghiem.vo@nois.vn'\n",
    "\n",
    "\n",
    "def get_users(query: str = None):\n",
    "    return requests.get(url + '/api/User').json()['data']\n",
    "\n",
    "def delAll(ID: str):\n",
    "    lst = []\n",
    "    get_reply = requests.get(url + f\"/api/LeaveApplication/{ID}\").json()\n",
    "    for i in get_reply['data']:\n",
    "        lst.append(i['id'])\n",
    "        \n",
    "    for i in lst:\n",
    "        del_reply = requests.delete(url + f\"/api/LeaveApplication/{i}\")\n",
    "        print(del_reply.text)\n",
    "\n",
    "def get_user_by_email(email):\n",
    "    response = requests.get(url + f'/api/User/me?email={email}')\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['data']\n",
    "    \n",
    "    return f'Error: {response.status_code}'\n",
    "\n",
    "def get_user_by_id(ID: str):\n",
    "    reply = requests.get(url + f'/api/User/me?id={ID}')\n",
    "    if response.status_code != 200:\n",
    "        return f'Error: {response.status_code}'\n",
    "    \n",
    "    if not reply.json()['data']:\n",
    "        return \"Wrong ID, recheck your input.\"\n",
    "    \n",
    "    return reply.json()['data']\n",
    "\n",
    "def check_manager_name(name):\n",
    "    response = requests.get(url + '/api/User/manager-users').json()['data']\n",
    "    \n",
    "    for data in response:\n",
    "        if data['fullName'].lower() == name.lower(): \n",
    "            return data['id']\n",
    "        \n",
    "    return -1\n",
    "def check_manager_id(managerId):\n",
    "    response = requests.get(url + '/api/User/manager-users').json()['data']\n",
    "    \n",
    "    for data in response:\n",
    "        if data['id'] == int(managerId): \n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "    \n",
    "def post_method(user_id, manager_id, start_date, end_date):\n",
    "    start_datetime = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_datetime = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    num_days = 0\n",
    "    \n",
    "    if end_datetime == start_datetime:\n",
    "        num_days = 0.5\n",
    "    else:\n",
    "        num_days = (end_datetime - start_datetime).days\n",
    "        \n",
    "    response = requests.post('https://hrm-nois-fake.azurewebsites.net/api/LeaveApplication/Submit', json = {\n",
    "        \"userId\": user_id,\n",
    "        \"reviewUserId\": manager_id,\n",
    "        \"relatedUserId\": \"string\",\n",
    "        \"fromDate\": start_date,\n",
    "        \"toDate\": end_date,\n",
    "        \"leaveApplicationTypeId\": 0,\n",
    "        \"leaveApplicationNote\": \"string\",\n",
    "        \"periodType\": 0,\n",
    "        \"numberOffDay\": num_days\n",
    "    })\n",
    "    \n",
    "    return response\n",
    "    \n",
    "lst = []\n",
    "def submitLeaveApplication(args: str):\n",
    "    global lst\n",
    "    lst = args.split(', ')\n",
    "    \n",
    "    if len(lst) != 4:\n",
    "        return \"Incorrect number of arguments, this function requires 4 arguments: user's id, manager's id, start date and end date.\"\n",
    "    \n",
    "    \n",
    "    if '-' not in lst[0]:\n",
    "        return \"Incorrect ID. You can find the correct ID by using the HRM get by email tool.\"\n",
    "    \n",
    "    if check_manager_name(lst[1]) == -1 and check_manager_id(lst[1]) == False:\n",
    "        return \"Ask the user for the correct manager's name. The user either didn't give you a name or gave you the wrong name.\"\n",
    "    \n",
    "    if '-' not in lst[2]:\n",
    "        return \"Ask the user when they want to start their leave. Infer the date based on the user's answer.\"\n",
    "    \n",
    "    if datetime.strptime(lst[2], \"%Y-%m-%d\") < datetime.strptime(date, \"%Y-%m-%d\"):\n",
    "        return \"Start date cannot be earlier than current date, ask the user for another date.\"\n",
    "    \n",
    "    if '-' not in lst[3]:\n",
    "        return \"Ask the user when they want to end their leave. Infer the date based on the user's answer.\"\n",
    "    \n",
    "    if datetime.strptime(lst[3], \"%Y-%m-%d\") < datetime.strptime(lst[2], \"%Y-%m-%d\"):\n",
    "        return \"End date cannot be earlier than start date, ask the user for another date.\"\n",
    "    \n",
    "    print(\"\\nUserId: \", lst[0])\n",
    "    print(\"ReviewerId: \", lst[1])\n",
    "    print(\"Start date: \", lst[2])\n",
    "    print(\"End date: \", lst[3])\n",
    "    \n",
    "    reply = post_method(lst[0], int(lst[1]), lst[2], lst[3])\n",
    "    \n",
    "#     return reply.text\n",
    "    return '{\"message\": \"OK\"}'\n",
    "        \n",
    "tools = [    \n",
    "    \n",
    "    Tool(\n",
    "        name='HRM get by name',\n",
    "        func=check_manager_name,\n",
    "        description='useful for getting the manager\\'s id by manager\\'s name. Input is a manager\\'s name.'\n",
    "    ),\n",
    "    \n",
    "    Tool(\n",
    "        name='HRM get by email',\n",
    "        func=get_user_by_email,\n",
    "        description='useful for getting the user\\'s id by user\\'s email.'\n",
    "    ),\n",
    "    \n",
    "    Tool(\n",
    "        name='HRM submit leave',\n",
    "        func=submitLeaveApplication,\n",
    "        description=f'''useful for submitting leave applications for a specific user.\n",
    "Input must include 4 parameters concatenated into a string separated by a comma and space, which are: \n",
    "1. user's id: you get from the given email. \n",
    "2. the id of manager who approve user's application: firstly, ask user the name of the manager and then find manager's id by name.\n",
    "3. start date: ask the user when they want to start their leave.\n",
    "4. end date: ask the user when they want to end their leave.\n",
    "Check to ensure that 4 parameters are got correctly according to form: user's id, manager's name, start date, end date.\n",
    "\n",
    "'''\n",
    "    )\n",
    "]\n",
    "\n",
    "# Example: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, LÝ MINH QUÂN, 2023-07-10, 2023-07-11\n",
    "\n",
    "human = load_tools(['human'])\n",
    "\n",
    "tools.extend(human)\n",
    "\n",
    "f'''If you cannot answer by using only 1 tool, try using other provided tools.\n",
    "If you cannot get any results from tools, say you don't know.\n",
    "Do not use any other sources other than the ones you obtain from tools.\n",
    "Suppose the current date is {date} (Year-Month-Day).'''\n",
    "\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(date)\n",
    "\n",
    "prefix = f\"\"\"You are an intelligent assistant helping users interact with system called HRM through the use of tools.\n",
    "Answer in the user's language.\n",
    "The user chatting with you own the email: {email}\n",
    "You have access to the following tools:\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "\n",
    "Examples: \n",
    "\n",
    "Observation: The user chatting with you own the email nghiem.vo@nois.vn.\n",
    "Thought: find the user's id by user's email.\n",
    "Action: HRM get by email\n",
    "Observation: [65255df1-d4c3-479b-a4b8-d63cb3db2beb] , [manager's id], [start date], [end date]\n",
    "Thought: Ask the user for the manager's name.\n",
    "Action: Human\n",
    "Action Input: \n",
    "Thought: find the manager's id by manager's name.\n",
    "Action: HRM get by name\n",
    "Observation: [65255df1-d4c3-479b-a4b8-d63cb3db2beb] , [139], [start date], [end date]\n",
    "Thought: ask user the date of starting leaving (according the format Year-Month-Day)?\n",
    "Action: Human\n",
    "Action Input: \n",
    "Observation: [65255df1-d4c3-479b-a4b8-d63cb3db2beb] , [139], [2023-07-17], [end date]\n",
    "Thought: ask user the date of ending leaving (according the format Year-Month-Day)?\n",
    "Action: Human\n",
    "Action Input: \n",
    "Observation: [65255df1-d4c3-479b-a4b8-d63cb3db2beb] , [139], [2023-07-17], [2023-07-18]\n",
    "Thought: Got all details for submitting.\n",
    "Action: HRM submit leave.\n",
    "Observation: Successfully.\n",
    "\n",
    "Begin!\n",
    "\n",
    "{context}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"context\", \"agent_scratchpad\"],\n",
    ")\n",
    "\n",
    "history = ConversationBufferWindowMemory(k=3, memory_key=\"context\", human_prefix='User', ai_prefix='Assistant')\n",
    "\n",
    "llm_chain = LLMChain(llm=llm3, prompt=prompt)\n",
    "\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True, stop=[\"\\nObservation:\", \"<|im_end|>\", \"<|im_sep|>\"])\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools, \n",
    "    verbose=True,\n",
    "    handle_parsing_errors=\"True\",\n",
    "    memory=history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "feefa094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an intelligent assistant helping users interact with system called HRM through the use of tools.\n",
      "Answer in the user's language.\n",
      "The user chatting with you own the email: nghiem.vo@nois.vn\n",
      "You have access to the following tools:\n",
      "\n",
      "HRM get by name: useful for getting the manager's id by manager's name. Input is a manager's name.\n",
      "HRM get by email: useful for getting the user's id by user's email.\n",
      "HRM submit leave: useful for submitting leave applications for a specific user.\n",
      "Input must include 4 parameters concatenated into a string separated by a comma and space, which are: \n",
      "1. user's id: you get from the given email. \n",
      "2. the id of manager who approve user's application: firstly, ask user the name of the manager and then find manager's id by name.\n",
      "3. start date: ask the user when they want to start their leave.\n",
      "4. end date: ask the user when they want to end their leave.\n",
      "Check to ensure that 4 parameters are got correctly according to form: user's id, manager's name, start date, end date.\n",
      "\n",
      "\n",
      "Human: You can ask a human for guidance when you think you got stuck or you are not sure what to do next. The input should be a question for the human.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [HRM get by name, HRM get by email, HRM submit leave, Human]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "\n",
      "\n",
      "Examples: \n",
      "\n",
      "Observation: The user chatting with you own the email nghiem.vo@nois.vn.\n",
      "Thought: find the user's id by user's email.\n",
      "Action: HRM get by email\n",
      "Observation: [65255df1-d4c3-479b-a4b8-d63cb3db2beb] , [manager's id], [start date], [end date]\n",
      "Thought: Ask the user for the manager's name.\n",
      "Action: Human\n",
      "Action Input: \n",
      "Thought: find the manager's id by manager's name.\n",
      "Action: HRM get by name\n",
      "Observation: [65255df1-d4c3-479b-a4b8-d63cb3db2beb] , [139], [start date], [end date]\n",
      "Thought: ask user the date of starting leaving (according the format Year-Month-Day)?\n",
      "Action: Human\n",
      "Action Input: \n",
      "Observation: [65255df1-d4c3-479b-a4b8-d63cb3db2beb] , [139], [2023-07-17], [end date]\n",
      "Thought: ask user the date of ending leaving (according the format Year-Month-Day)?\n",
      "Action: Human\n",
      "Action Input: \n",
      "Observation: [65255df1-d4c3-479b-a4b8-d63cb3db2beb] , [139], [2023-07-17], [2023-07-18]\n",
      "Thought: Got all details for submitting.\n",
      "Action: HRM submit leave.\n",
      "Observation: Successfully.\n",
      "\n",
      "Begin!\n",
      "\n",
      "{context}\n",
      "Question: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8a6d3ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: The user wants to submit a leave application.\n",
      "Action: HRM get by email\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action Input:' after 'Action:'\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through an Azure support request at: https://go.microsoft.com/fwlink/?linkid=2213926 if the error persists. (Please include the request ID bd478b96-8510-414b-ad30-8cc3653714a9 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through an Azure support request at: https://go.microsoft.com/fwlink/?linkid=2213926 if the error persists. (Please include the request ID bd478b96-8510-414b-ad30-8cc3653714a9 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through an Azure support request at: https://go.microsoft.com/fwlink/?linkid=2213926 if the error persists. (Please include the request ID bd478b96-8510-414b-ad30-8cc3653714a9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Content-Length': '412', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '5f9a06a8-8e7b-4672-a027-acd5aec5b387', 'x-content-type-options': 'nosniff', 'openai-processing-ms': '30020.3595', 'x-ms-region': 'East US', 'x-request-id': 'bd478b96-8510-414b-ad30-8cc3653714a9', 'ms-azureml-model-error-reason': 'model_error', 'ms-azureml-model-error-statuscode': '500', 'x-ms-client-request-id': '5f9a06a8-8e7b-4672-a027-acd5aec5b387', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'azureml-model-session': 'turbo-06292023', 'azureml-model-group': 'online', 'Date': 'Tue, 11 Jul 2023 08:10:18 GMT'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to provide the HRM get by email action input.\n",
      "Action: HRM get by email\n",
      "Action Input: nghiem.vo@nois.vn\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{'id': '65255df1-d4c3-479b-a4b8-d63cb3db2beb', 'name': 'Nghiem Vo', 'email': 'nghiem.vo@nois.vn', 'fullName': 'VÕ NGỌC DUY NGHIÊM', 'jobTitle': 'Lập trình viên', 'mobilePhone': '0843961713', 'birthday': '1999', 'offDay': 3, 'yearOffDay': 0, 'maxDayOff': 10, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 0, 'gender': 0, 'personalEmail': '', 'avatar': '', 'acceptOfferDate': '', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': 'Development Unit 1', 'groupUserId': '', 'groupUserName': '', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '', 'issuedBy': '', 'placeOfTemporaryResidence': '', 'placeOfResidence': '', 'relativeName': '', 'relationship': '', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': 'VIB', 'bankBranch': '', 'bankAccountNumber': '863644436', 'birthPlace': 'Los Angeles', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '', 'education': 'Bach Khoa University', 'jobId': '', 'jobName': 'chatbot', 'levelId': '', 'levelName': 'Internship'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have retrieved the user's information. Now I need to ask the user for the manager's name.\n",
      "Action: Human\n",
      "Action Input: What is the name of your manager?\u001b[0m\n",
      "\n",
      "What is the name of your manager?\n",
      "trần đăng ninh\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mtrần đăng ninh\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through an Azure support request at: https://go.microsoft.com/fwlink/?linkid=2213926 if the error persists. (Please include the request ID 2849b02a-fee6-4e90-b3f2-ea0216989fe3 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through an Azure support request at: https://go.microsoft.com/fwlink/?linkid=2213926 if the error persists. (Please include the request ID 2849b02a-fee6-4e90-b3f2-ea0216989fe3 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through an Azure support request at: https://go.microsoft.com/fwlink/?linkid=2213926 if the error persists. (Please include the request ID 2849b02a-fee6-4e90-b3f2-ea0216989fe3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Content-Length': '412', 'Content-Type': 'application/json', 'access-control-allow-origin': '*', 'apim-request-id': '9c51c33b-608a-4902-8dad-18aea18f536e', 'x-content-type-options': 'nosniff', 'openai-processing-ms': '30034.5742', 'x-ms-region': 'East US', 'x-request-id': '2849b02a-fee6-4e90-b3f2-ea0216989fe3', 'ms-azureml-model-error-reason': 'model_error', 'ms-azureml-model-error-statuscode': '500', 'x-ms-client-request-id': '9c51c33b-608a-4902-8dad-18aea18f536e', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'azureml-model-session': 'turbo-06292023', 'azureml-model-group': 'online', 'Date': 'Tue, 11 Jul 2023 08:10:59 GMT'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to find the manager's id by manager's name.\n",
      "Action: HRM get by name\n",
      "Action Input: trần đăng ninh\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m119\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have retrieved the manager's id. Now I need to ask the user for the start date of their leave.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:'\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to ask the user for the start date of their leave.\n",
      "Action: Human\n",
      "Action Input: When do you want to start your leave? (Please provide the date in the format Year-Month-Day)\u001b[0m\n",
      "\n",
      "When do you want to start your leave? (Please provide the date in the format Year-Month-Day)\n",
      "2023-07-12\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m2023-07-12\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have retrieved the start date of the user's leave. Now I need to ask the user for the end date of their leave.\n",
      "Action: Human\n",
      "Action Input: When do you want to end your leave? (Please provide the date in the format Year-Month-Day)\u001b[0m\n",
      "\n",
      "When do you want to end your leave? (Please provide the date in the format Year-Month-Day)\n",
      "2023-07-13\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m2023-07-13\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have retrieved the end date of the user's leave. Now I have all the necessary information to submit the leave application.\n",
      "Action: HRM submit leave\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action Input:' after 'Action:'\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to provide the HRM submit leave action input.\n",
      "Action: HRM submit leave\n",
      "Action Input: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, 119, 2023-07-12, 2023-07-13\u001b[0m\n",
      "UserId:  65255df1-d4c3-479b-a4b8-d63cb3db2beb\n",
      "ReviewerId:  119\n",
      "Start date:  2023-07-12\n",
      "End date:  2023-07-13\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{\"message\": \"OK\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe leave application has been successfully submitted.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:'\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe leave application has been successfully submitted.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:'\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe leave application has been successfully submitted.\n",
      "Final Answer: The leave application has been successfully submitted.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "history.clear()\n",
    "answer = agent_chain.run(input=\"I'd like to submit a leave application.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9312dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent stopped due to iteration limit or time limit.\n",
      "[\"[user's id]\", \"[manager's name]\", '[start date]', '[end date]']\n"
     ]
    }
   ],
   "source": [
    "print(answer)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b293b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "delAll(\"65255df1-d4c3-479b-a4b8-d63cb3db2beb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b48ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
