{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb122fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains import LLMChain, APIChain\n",
    "from langchain.chains.api.prompt import API_RESPONSE_PROMPT\n",
    "from langchain.schema import Document\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import ZeroShotAgent, AgentExecutor, AgentType, initialize_agent, Tool, load_tools\n",
    "from langchain.agents.agent_toolkits.openapi import planner\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.api import open_meteo_docs\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_endpoint = 'https://search-service01.search.windows.net'\n",
    "search_key = '73Swa5YqUR5IRMwUIqOH6ww2YBm3SveLv7rDmZVXtIAzSeBjEQe9'\n",
    "private_index_name = \"nois-private-v3-index\"\n",
    "\n",
    "retriever_private = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=private_index_name,\n",
    "    credential=AzureKeyCredential(search_key),\n",
    "    b=0.0,\n",
    "    k1=0.3,\n",
    "    searchMode=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8b195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1171\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "def count_tokens(s):\n",
    "    return len(enc.encode(s))\n",
    "string = '''[{'id': '262aa143-307a-4b9f-848d-1e6bf2e5cacb', 'name': 'Hung Bui', 'email': 'hung.bui@nois.vn', 'fullName': 'BÙI TUẤN HƯNG', 'jobTitle': 'Lập trình viên', 'mobilePhone': '0966772170', 'birthday': '1997-08-17T00:00:00', 'offDay': 0.5, 'yearOffDay': 6, 'maxDayOff': 15, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 1, 'gender': 1, 'personalEmail': 'hungbt.dev@gmail.com', 'avatar': 'https://noishrm.blob.core.windows.net/avatar/8fec9283-e82f-43ec-8f61-addb732dabcb.jpeg', 'acceptOfferDate': '2022-10-31T00:00:00', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': 'Development Unit 1', 'groupUserId': '', 'groupUserName': 'Nhân viên chính thức', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '2021-08-10T00:00:00', 'issuedBy': 'Cục trưởng CCS QLHC về TTXH', 'placeOfTemporaryResidence': '502/15/2 Thống Nhất, p.16, Gò Vấp, TP.HCM', 'placeOfResidence': '161 Đường 458, Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM', 'relativeName': 'Lê Thị Kiều', 'relationship': 'Mẹ', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': 'Vietcombank', 'bankBranch': 'DONG SAI GON-PGD THANH DA', 'bankAccountNumber': '0531002579897', 'birthPlace': 'Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '8460719408', 'education': '', 'jobId': '', 'jobName': 'Developer', 'levelId': '', 'levelName': ''}, {'id': '72fb1693-9cc1-4923-b0a4-afb18469613c', 'name': 'KHASNH BUIF', 'email': '', 'fullName': '', 'jobTitle': '', 'mobilePhone': '', 'birthday': '', 'offDay': 1, 'yearOffDay': 0, 'maxDayOff': 0, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 0, 'gender': 0, 'personalEmail': '', 'avatar': '', 'acceptOfferDate': '', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': '', 'groupUserId': '', 'groupUserName': '', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '', 'issuedBy': '', 'placeOfTemporaryResidence': '', 'placeOfResidence': '', 'relativeName': '', 'relationship': '', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': '', 'bankBranch': '', 'bankAccountNumber': '', 'birthPlace': '', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '', 'education': '', 'jobId': '', 'jobName': '', 'levelId': '', 'levelName': ''}, {'id': 'c8604118-7db6-4e08-8926-5bd8c81bce81', 'name': 'Bao Ho', 'email': 'honguyenngocbao@gmail.com', 'fullName': 'HỒ NGUYỄN NGỌC BẢO', 'jobTitle': '', 'mobilePhone': '', 'birthday': '', 'offDay': 0, 'yearOffDay': 0, 'maxDayOff': 0, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 0, 'gender': 0, 'personalEmail': '', 'avatar': '', 'acceptOfferDate': '', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': '', 'groupUserId': '', 'groupUserName': '', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '', 'issuedBy': '', 'placeOfTemporaryResidence': '', 'placeOfResidence': '', 'relativeName': '', 'relationship': '', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': '', 'bankBranch': '', 'bankAccountNumber': '', 'birthPlace': '', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '', 'education': '', 'jobId': '', 'jobName': '', 'levelId': '', 'levelName': ''}]'''\n",
    "\n",
    "print(count_tokens(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde3db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n",
      "WARNING! top_p is not default parameter.\n",
      "                    top_p was transferred to model_kwargs.\n",
      "                    Please confirm that top_p is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache=None verbose=False callbacks=None callback_manager=None tags=None metadata=None client=<class 'openai.api_resources.chat_completion.ChatCompletion'> model_name='gpt-3.5-turbo' temperature=0.0 model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']} openai_api_key='400568d9a16740b88aff437480544a39' openai_api_base='https://openai-nois-intern.openai.azure.com/' openai_organization='' openai_proxy='' request_timeout=None max_retries=6 streaming=False n=1 max_tokens=600 tiktoken_model_name=None deployment_name='gpt-35-turbo' openai_api_type='azure' openai_api_version='2023-03-15-preview'\n",
      "761\n"
     ]
    }
   ],
   "source": [
    "# Load up your LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0.5,\n",
    "    max_tokens=450\n",
    ")\n",
    "\n",
    "llm2 = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0,\n",
    "    max_tokens=600,\n",
    "    stop=['\\n', '<|im_end|>', '<|im_sep|>']\n",
    ")\n",
    "\n",
    "llm3 = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo-16k',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0.0,\n",
    "    max_tokens=600,\n",
    "    top_p = 0.65\n",
    ")\n",
    "\n",
    "history = []\n",
    "history_entry = 1\n",
    "\n",
    "def get_history_as_txt():\n",
    "    txt = \"\"\n",
    "    hist = history[::-1]\n",
    "    \n",
    "    for i in hist[:3]:\n",
    "        txt += f\"\\n<|im_start|>user\\n{i['user']}\\n<|im_end|>\\n\"\n",
    "        txt += f\"<|im_start|>assistant\\n{i['AI']}\\n<|im_end|>\"\n",
    "        \n",
    "    return txt\n",
    "\n",
    "def add_to_history(user_msg, ai_msg):\n",
    "    history.append({'user': user_msg, 'AI': ai_msg})\n",
    "    \n",
    "def save_history_to_file():\n",
    "    global history_entry\n",
    "    file = open(f\"chatbot-cases/chat-{history_entry}.txt\", 'w', encoding='utf-8')\n",
    "    file.write(get_history_as_txt())\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    history_entry += 1\n",
    "    \n",
    "def doc_to_str(doc):\n",
    "    string = \"\"\n",
    "    for i in doc:\n",
    "        string += i.page_content\n",
    "        \n",
    "    return string\n",
    "\n",
    "print(llm2)\n",
    "doc = open_meteo_docs.OPEN_METEO_DOCS\n",
    "print(llm2.get_num_tokens(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440dbba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE URL: https://hrm-nois-fake.azurewebsites.net/\n",
      "\n",
      "HRM system\n",
      "API DOCUMENTATION\n",
      "Endpoints:\n",
      "- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\n",
      "- /api/User/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\n",
      "- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\n",
      "API token length: 128\n"
     ]
    }
   ],
   "source": [
    "# print(open_meteo_docs.OPEN_METEO_DOCS)\n",
    "hrm_doc = open(\"HRM_API_DOC.txt\", 'r', encoding='utf-8')\n",
    "api_doc = hrm_doc.read()\n",
    "print(api_doc)\n",
    "print(f\"API token length: {count_tokens(api_doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16b02489",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_new = APIChain.from_llm_and_api_docs(llm2, api_doc, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69e00702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lc_kwargs={'api_request_chain': LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text'), 'api_answer_chain': LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text'), 'requests_wrapper': TextRequestsWrapper(headers=None, aiosession=None), 'api_docs': \"BASE URL: https://hrm-nois-fake.azurewebsites.net/\\n\\nHRM system\\nAPI DOCUMENTATION\\nEndpoints:\\n- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\\n- /api/User/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\", 'verbose': True} memory=None callbacks=None callback_manager=None verbose=True api_request_chain=LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text') api_answer_chain=LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text') requests_wrapper=TextRequestsWrapper(headers=None, aiosession=None) api_docs=\"BASE URL: https://hrm-nois-fake.azurewebsites.net/\\n\\nHRM system\\nAPI DOCUMENTATION\\nEndpoints:\\n- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\\n- /api/User/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\" question_key='question' output_key='output'\n"
     ]
    }
   ],
   "source": [
    "print(chain_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2962f4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mhttps://hrm-nois-fake.azurewebsites.net/api/User\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{\"message\":\"OK\",\"data\":[{\"id\":\"262aa143-307a-4b9f-848d-1e6bf2e5cacb\",\"name\":\"Hung Bui\",\"email\":\"hung.bui@nois.vn\",\"fullName\":\"BÙI TUẤN HƯNG\",\"jobTitle\":\"Lập trình viên\",\"mobilePhone\":\"0966772170\",\"birthday\":\"1997-08-17T00:00:00\",\"offDay\":0.5,\"yearOffDay\":6,\"maxDayOff\":15,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":1,\"gender\":1,\"personalEmail\":\"hungbt.dev@gmail.com\",\"avatar\":\"https://noishrm.blob.core.windows.net/avatar/8fec9283-e82f-43ec-8f61-addb732dabcb.jpeg\",\"acceptOfferDate\":\"2022-10-31T00:00:00\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"Development Unit 1\",\"groupUserId\":\"\",\"groupUserName\":\"Nhân viên chính thức\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"2021-08-10T00:00:00\",\"issuedBy\":\"Cục trưởng CCS QLHC về TTXH\",\"placeOfTemporaryResidence\":\"502/15/2 Thống Nhất, p.16, Gò Vấp, TP.HCM\",\"placeOfResidence\":\"161 Đường 458, Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM\",\"relativeName\":\"Lê Thị Kiều\",\"relationship\":\"Mẹ\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"Vietcombank\",\"bankBranch\":\"DONG SAI GON-PGD THANH DA\",\"bankAccountNumber\":\"0531002579897\",\"birthPlace\":\"Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"8460719408\",\"education\":\"\",\"jobId\":\"\",\"jobName\":\"Developer\",\"levelId\":\"\",\"levelName\":\"\"},{\"id\":\"c8604118-7db6-4e08-8926-5bd8c81bce81\",\"name\":\"Bao Ho\",\"email\":\"honguyenngocbao@gmail.com\",\"fullName\":\"HỒ NGUYỄN NGỌC BẢO\",\"jobTitle\":\"\",\"mobilePhone\":\"\",\"birthday\":\"\",\"offDay\":0,\"yearOffDay\":0,\"maxDayOff\":0,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":0,\"gender\":0,\"personalEmail\":\"\",\"avatar\":\"\",\"acceptOfferDate\":\"\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"\",\"groupUserId\":\"\",\"groupUserName\":\"\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"\",\"issuedBy\":\"\",\"placeOfTemporaryResidence\":\"\",\"placeOfResidence\":\"\",\"relativeName\":\"\",\"relationship\":\"\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"\",\"bankBranch\":\"\",\"bankAccountNumber\":\"\",\"birthPlace\":\"\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"\",\"education\":\"\",\"jobId\":\"\",\"jobName\":\"\",\"levelId\":\"\",\"levelName\":\"\"}]}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"Users's birthday'?\",\n",
       " 'output': \"The response from the API provides information about two users. The first user's name is Hung Bui and their birthday is on August 17, 1997. The second user's name is Bao Ho, but their birthday is not provided.\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new(\"Users's birthday'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78b1d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-10\n"
     ]
    }
   ],
   "source": [
    "url = \"https://hrm-nois-fake.azurewebsites.net/\"\n",
    "date = str(datetime.now().date())\n",
    "\n",
    "def get_users(query: str = None):\n",
    "    return requests.get(url + '/api/User').json()['data']\n",
    "\n",
    "def get_user_through_email(email):\n",
    "    response = requests.get(url + f'/api/User/me?email={email}')\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['data']\n",
    "    \n",
    "    return f'Error: {response.status_code}'\n",
    "\n",
    "def get_user_by_id(ID: str):\n",
    "    reply = requests.get(url + f'/api/User/me?id={ID}')\n",
    "    if response.status_code != 200:\n",
    "        return f'Error: {response.status_code}'\n",
    "    \n",
    "    if not reply.json()['data']:\n",
    "        return \"Wrong ID, recheck your input.\"\n",
    "    \n",
    "    return reply.json()['data']\n",
    "\n",
    "def check_manager_name(name):\n",
    "    response = requests.get(url + '/api/User/manager-users').json()['data']\n",
    "    \n",
    "    for data in response:\n",
    "        if data['fullName'].lower() == name.lower(): \n",
    "            return data['id']\n",
    "        \n",
    "    return -1\n",
    "\n",
    "def post_method(idd, name, num_days, start_date=str(datetime.now().date())):\n",
    "    end_date = datetime.strptime(start_date, \"%Y-%m-%d\").date() + timedelta(days=num_days)\n",
    "    \n",
    "    response = requests.post('https://hrm-nois-fake.azurewebsites.net/api/LeaveApplication/Submit', json = {\n",
    "        \"userId\": idd,\n",
    "        \"reviewUserId\": name,\n",
    "        \"relatedUserId\": \"string\",\n",
    "        \"fromDate\": start_date,\n",
    "        \"toDate\": str(end_date),\n",
    "        \"leaveApplicationTypeId\": 0,\n",
    "        \"leaveApplicationNote\": \"string\",\n",
    "        \"periodType\": 0,\n",
    "        \"numberOffDay\": num_days\n",
    "    })\n",
    "    \n",
    "    return response\n",
    "    \n",
    "lst = []\n",
    "def submitLeaveApplication(args: str):\n",
    "    global lst\n",
    "    lst = args.split(', ')\n",
    "    \n",
    "    if len(lst) != 4:\n",
    "        return \"Incorrect number of arguments, this function requires 4 arguments: user's id, reviewer's id, number of leave days and start date.\"\n",
    "    \n",
    "    manager_id = -1 if '[' in lst[1] else check_manager_name(lst[1])\n",
    "    \"You must ask the user to provide the manager's name correctly.\"\n",
    "    \n",
    "    if '-' not in lst[0]:\n",
    "        return \"Incorrect ID. You can find the correct ID by using the HRM get by email tool.\"\n",
    "    elif manager_id == -1:\n",
    "        return \"Ask the user for the correct manager's name.\"\n",
    "    elif not lst[2].isdigit():\n",
    "        return \"Leave days must be a number. Ask the user to provide you with a number.\"\n",
    "    elif '-' not in lst[3]:\n",
    "        return \"Ask the user when they want to start their leave. Note that there are no tools for calculating date, infer the date yourself.\"\n",
    "    \n",
    "    lst[2] = int(lst[2])\n",
    "    \n",
    "    print(\"\\nUserId: \", lst[0])\n",
    "    print(\"ReviewerId: \", manager_id)\n",
    "    print(\"Number of days: \", lst[2])\n",
    "    \n",
    "    try:\n",
    "        print(\"Start date: \", lst[3])\n",
    "    except Exception:\n",
    "        print(\"No dates given.\")  \n",
    "    \n",
    "    reply = post_method(lst[0], manager_id, lst[2], lst[3])\n",
    "    \n",
    "    return reply.text\n",
    "#     return '{\"message\": \"OK\"}'\n",
    "        \n",
    "tools = [\n",
    "    Tool(\n",
    "        name='HRM get all',\n",
    "        func=get_users,\n",
    "        description='useful for getting details of all users. No input necessary.'\n",
    "    ),\n",
    "    \n",
    "    Tool(\n",
    "        name='HRM get by id',\n",
    "        func=get_user_by_id,\n",
    "        description='useful for getting details of a specific user by ID. Input is a user\\'s Id.'\n",
    "    ),\n",
    "    \n",
    "    Tool(\n",
    "        name='HRM get by email',\n",
    "        func=get_user_through_email,\n",
    "        description='useful for getting details of a specific user by email. Input is a user\\'s email.'\n",
    "    ),\n",
    "    \n",
    "    Tool(\n",
    "        name='HRM submit leave',\n",
    "        func=submitLeaveApplication,\n",
    "        description=f'''useful for submitting leave applications for a specific user.\n",
    "Input must include 4 parameters concatenated into a string separated by a comma and space, which are: \n",
    "1. user's id: you get by email. \n",
    "2. the name of manager who approve user's application: you must ask user to provide.\n",
    "3. number of leave days: you must ask user to provide.\n",
    "4. start date: Ask the user when they want to start their leave and infer the date from their answer based on the given current date. Suppose the current date is {date} (Year-Month-Day).\n",
    "'''\n",
    "    )\n",
    "]\n",
    "\n",
    "# Example: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, LÝ MINH QUÂN, 4\n",
    "\n",
    "human = load_tools(['human'])\n",
    "\n",
    "tools.extend(human)\n",
    "\n",
    "'''If you cannot answer by using only 1 tool, try using other provided tools. If you cannot get any results from tools, say you don't know. Do not use any other sources other than the ones you obtain from tools.'''\n",
    "\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(date)\n",
    "\n",
    "prefix = f\"\"\"You are an intelligent assistant helping users interact with system called HRM through the use of tools.\n",
    "Answer in the user's language.\n",
    "The user chatting with you is named Nghiem Vo, with email nghiem.vo@nois.vn.\n",
    "Suppose the current date is {date} (Year-Month-Day).\n",
    "You have access to the following tools:\"\"\"\n",
    "\n",
    "suffix = \"\"\"Begin!\n",
    "\n",
    "{context}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"context\", \"agent_scratchpad\"],\n",
    ")\n",
    "\n",
    "history = ConversationBufferWindowMemory(k=3, memory_key=\"context\")\n",
    "\n",
    "llm_chain = LLMChain(llm=llm3, prompt=prompt)\n",
    "\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True, stop=[\"\\nObservation:\", \"<|im_end|>\", \"<|im_sep|>\"])\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools, \n",
    "    verbose=True,\n",
    "    handle_parsing_errors=\"Check your output, start your thoughs with with Thought:\",\n",
    "    memory=history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a6d3ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user wants to submit a leave application. I need to ask for the necessary information to submit the application.\n",
      "Action: HRM submit leave\n",
      "Action Input: nghiem.vo@nois.vn, [ask user for manager's name], [ask user for number of leave days], [ask user for start date]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIncorrect ID. You can find the correct ID by using the HRM get by email tool.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user provided an incorrect ID. I need to use the HRM get by email tool to find the correct ID.\n",
      "Action: HRM get by email\n",
      "Action Input: nghiem.vo@nois.vn\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{'id': '65255df1-d4c3-479b-a4b8-d63cb3db2beb', 'name': 'Nghiem Vo', 'email': 'nghiem.vo@nois.vn', 'fullName': 'VÕ NGỌC DUY NGHIÊM', 'jobTitle': 'Lập trình viên', 'mobilePhone': '0843961713', 'birthday': '1999', 'offDay': 9, 'yearOffDay': 0, 'maxDayOff': 10, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 0, 'gender': 0, 'personalEmail': '', 'avatar': '', 'acceptOfferDate': '', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': 'Development Unit 1', 'groupUserId': '', 'groupUserName': '', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '', 'issuedBy': '', 'placeOfTemporaryResidence': '', 'placeOfResidence': '', 'relativeName': '', 'relationship': '', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': 'VIB', 'bankBranch': '', 'bankAccountNumber': '863644436', 'birthPlace': 'Los Angeles', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '', 'education': 'Bach Khoa University', 'jobId': '', 'jobName': 'chatbot', 'levelId': '', 'levelName': 'Internship'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have retrieved the user's details. Now I can proceed with submitting the leave application.\n",
      "Action: HRM submit leave\n",
      "Action Input: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, [ask user for manager's name], [ask user for number of leave days], [ask user for start date]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAsk the user for the correct manager's name.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user needs to provide the correct manager's name. I should ask the user for the correct manager's name.\n",
      "Action: human\n",
      "Action Input: What is the correct manager's name?\u001b[0m\n",
      "\n",
      "What is the correct manager's name?\n",
      "lý minh quân\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mlý minh quân\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have all the necessary information to submit the leave application.\n",
      "Action: HRM submit leave\n",
      "Action Input: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, lý minh quân, [ask user for number of leave days], [ask user for start date]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLeave days must be a number. Ask the user to provide you with a number.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user provided an invalid input for the number of leave days. I need to ask the user to provide a valid number.\n",
      "Action: human\n",
      "Action Input: How many leave days would you like to apply for?\u001b[0m\n",
      "\n",
      "How many leave days would you like to apply for?\n",
      "3\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3m3\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user wants to apply for 3 leave days. Now I need to ask for the start date.\n",
      "Action: HRM submit leave\n",
      "Action Input: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, lý minh quân, 3, [ask user for start date]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAsk the user when they want to start their leave. Note that there are no tools for calculating date, infer the date yourself.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user needs to provide the start date for their leave application. I will ask the user for the start date and calculate the date based on the current date.\n",
      "Action: human\n",
      "Action Input: When would you like to start your leave?\u001b[0m\n",
      "\n",
      "When would you like to start your leave?\n",
      "3 days from now\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3m3 days from now\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user wants to start their leave 3 days from now. I will calculate the start date based on the current date.\n",
      "Action: HRM submit leave\n",
      "Action Input: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, lý minh quân, 3, 2023-07-13\u001b[0m\n",
      "UserId:  65255df1-d4c3-479b-a4b8-d63cb3db2beb\n",
      "ReviewerId:  139\n",
      "Number of days:  3\n",
      "Start date:  2023-07-13\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m{\"message\":\"OK\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: `I have successfully submitted the leave application for the user.`\u001b[0m\n",
      "Observation: Check your output, start your thoughs with with Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have successfully submitted the leave application for the user.\n",
      "Final Answer: The leave application has been submitted successfully.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = agent_chain.run(input=\"I'd like to submit a leave application.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9312dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent stopped due to iteration limit or time limit.\n",
      "['65255df1-d4c3-479b-a4b8-d63cb3db2beb', 'Lý Minh Quân', 3, '2023-07-15']\n"
     ]
    }
   ],
   "source": [
    "print(answer)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "92110788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [400]>\n"
     ]
    }
   ],
   "source": [
    "print(post_method('65255df1-d4c3-479b-a4b8-d63cb3db2beb', 'LÝ MINH QUÂN', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8056d557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 7, 10, 9, 36, 45, 941035)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ca3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
