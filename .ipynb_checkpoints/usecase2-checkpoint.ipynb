{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb122fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains import LLMChain, APIChain\n",
    "from langchain.chains.api.prompt import API_RESPONSE_PROMPT\n",
    "from langchain.schema import Document\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import ZeroShotAgent, AgentExecutor, AgentType, initialize_agent, Tool, load_tools\n",
    "from langchain.agents.agent_toolkits.openapi import planner\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.api import open_meteo_docs\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_endpoint = 'https://search-service01.search.windows.net'\n",
    "search_key = '73Swa5YqUR5IRMwUIqOH6ww2YBm3SveLv7rDmZVXtIAzSeBjEQe9'\n",
    "private_index_name = \"nois-private-v3-index\"\n",
    "\n",
    "retriever_private = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=private_index_name,\n",
    "    credential=AzureKeyCredential(search_key),\n",
    "    b=0.0,\n",
    "    k1=0.3,\n",
    "    searchMode=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8b195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1171\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "def count_tokens(s):\n",
    "    return len(enc.encode(s))\n",
    "string = '''[{'id': '262aa143-307a-4b9f-848d-1e6bf2e5cacb', 'name': 'Hung Bui', 'email': 'hung.bui@nois.vn', 'fullName': 'BÙI TUẤN HƯNG', 'jobTitle': 'Lập trình viên', 'mobilePhone': '0966772170', 'birthday': '1997-08-17T00:00:00', 'offDay': 0.5, 'yearOffDay': 6, 'maxDayOff': 15, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 1, 'gender': 1, 'personalEmail': 'hungbt.dev@gmail.com', 'avatar': 'https://noishrm.blob.core.windows.net/avatar/8fec9283-e82f-43ec-8f61-addb732dabcb.jpeg', 'acceptOfferDate': '2022-10-31T00:00:00', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': 'Development Unit 1', 'groupUserId': '', 'groupUserName': 'Nhân viên chính thức', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '2021-08-10T00:00:00', 'issuedBy': 'Cục trưởng CCS QLHC về TTXH', 'placeOfTemporaryResidence': '502/15/2 Thống Nhất, p.16, Gò Vấp, TP.HCM', 'placeOfResidence': '161 Đường 458, Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM', 'relativeName': 'Lê Thị Kiều', 'relationship': 'Mẹ', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': 'Vietcombank', 'bankBranch': 'DONG SAI GON-PGD THANH DA', 'bankAccountNumber': '0531002579897', 'birthPlace': 'Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '8460719408', 'education': '', 'jobId': '', 'jobName': 'Developer', 'levelId': '', 'levelName': ''}, {'id': '72fb1693-9cc1-4923-b0a4-afb18469613c', 'name': 'KHASNH BUIF', 'email': '', 'fullName': '', 'jobTitle': '', 'mobilePhone': '', 'birthday': '', 'offDay': 1, 'yearOffDay': 0, 'maxDayOff': 0, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 0, 'gender': 0, 'personalEmail': '', 'avatar': '', 'acceptOfferDate': '', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': '', 'groupUserId': '', 'groupUserName': '', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '', 'issuedBy': '', 'placeOfTemporaryResidence': '', 'placeOfResidence': '', 'relativeName': '', 'relationship': '', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': '', 'bankBranch': '', 'bankAccountNumber': '', 'birthPlace': '', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '', 'education': '', 'jobId': '', 'jobName': '', 'levelId': '', 'levelName': ''}, {'id': 'c8604118-7db6-4e08-8926-5bd8c81bce81', 'name': 'Bao Ho', 'email': 'honguyenngocbao@gmail.com', 'fullName': 'HỒ NGUYỄN NGỌC BẢO', 'jobTitle': '', 'mobilePhone': '', 'birthday': '', 'offDay': 0, 'yearOffDay': 0, 'maxDayOff': 0, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 0, 'gender': 0, 'personalEmail': '', 'avatar': '', 'acceptOfferDate': '', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '', 'managerFullName': '', 'departmentId': 0, 'departmentName': '', 'groupUserId': '', 'groupUserName': '', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '', 'issuedBy': '', 'placeOfTemporaryResidence': '', 'placeOfResidence': '', 'relativeName': '', 'relationship': '', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': '', 'bankBranch': '', 'bankAccountNumber': '', 'birthPlace': '', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '', 'education': '', 'jobId': '', 'jobName': '', 'levelId': '', 'levelName': ''}]'''\n",
    "\n",
    "print(count_tokens(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde3db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache=None verbose=False callbacks=None callback_manager=None tags=None metadata=None client=<class 'openai.api_resources.chat_completion.ChatCompletion'> model_name='gpt-3.5-turbo' temperature=0.0 model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']} openai_api_key='400568d9a16740b88aff437480544a39' openai_api_base='https://openai-nois-intern.openai.azure.com/' openai_organization='' openai_proxy='' request_timeout=None max_retries=6 streaming=False n=1 max_tokens=600 tiktoken_model_name=None deployment_name='gpt-35-turbo' openai_api_type='azure' openai_api_version='2023-03-15-preview'\n",
      "761\n"
     ]
    }
   ],
   "source": [
    "# Load up your LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0.5,\n",
    "    max_tokens=450\n",
    ")\n",
    "\n",
    "llm2 = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0,\n",
    "    max_tokens=600,\n",
    "    stop=['\\n', '<|im_end|>', '<|im_sep|>']\n",
    ")\n",
    "\n",
    "llm3 = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0.5,\n",
    "    max_tokens=600\n",
    ")\n",
    "\n",
    "history = []\n",
    "history_entry = 1\n",
    "\n",
    "def get_history_as_txt():\n",
    "    txt = \"\"\n",
    "    hist = history[::-1]\n",
    "    \n",
    "    for i in hist[:3]:\n",
    "        txt += f\"\\n<|im_start|>user\\n{i['user']}\\n<|im_end|>\\n\"\n",
    "        txt += f\"<|im_start|>assistant\\n{i['AI']}\\n<|im_end|>\"\n",
    "        \n",
    "    return txt\n",
    "\n",
    "def add_to_history(user_msg, ai_msg):\n",
    "    history.append({'user': user_msg, 'AI': ai_msg})\n",
    "    \n",
    "def save_history_to_file():\n",
    "    global history_entry\n",
    "    file = open(f\"chatbot-cases/chat-{history_entry}.txt\", 'w', encoding='utf-8')\n",
    "    file.write(get_history_as_txt())\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    history_entry += 1\n",
    "    \n",
    "def doc_to_str(doc):\n",
    "    string = \"\"\n",
    "    for i in doc:\n",
    "        string += i.page_content\n",
    "        \n",
    "    return string\n",
    "\n",
    "print(llm2)\n",
    "doc = open_meteo_docs.OPEN_METEO_DOCS\n",
    "print(llm2.get_num_tokens(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440dbba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE URL: https://hrm-nois-fake.azurewebsites.net/\n",
      "\n",
      "HRM system\n",
      "API DOCUMENTATION\n",
      "Endpoints:\n",
      "- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\n",
      "- /api/User/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\n",
      "- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\n",
      "API token length: 128\n"
     ]
    }
   ],
   "source": [
    "# print(open_meteo_docs.OPEN_METEO_DOCS)\n",
    "hrm_doc = open(\"HRM_API_DOC.txt\", 'r', encoding='utf-8')\n",
    "api_doc = hrm_doc.read()\n",
    "print(api_doc)\n",
    "print(f\"API token length: {count_tokens(api_doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b02489",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_new = APIChain.from_llm_and_api_docs(llm2, api_doc, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e00702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lc_kwargs={'api_request_chain': LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text'), 'api_answer_chain': LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text'), 'requests_wrapper': TextRequestsWrapper(headers=None, aiosession=None), 'api_docs': \"BASE URL: https://hrm-nois-fake.azurewebsites.net/\\n\\nHRM system\\nAPI DOCUMENTATION\\nEndpoints:\\n- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\\n- /api/User/me/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/me/<email>: accepts an EMAIL string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/manager-users: Use GET with this endpoint to get name of a manager user.\\n- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\\n\", 'verbose': True} memory=None callbacks=None callback_manager=None verbose=True api_request_chain=LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text') api_answer_chain=LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text') requests_wrapper=TextRequestsWrapper(headers=None, aiosession=None) api_docs=\"BASE URL: https://hrm-nois-fake.azurewebsites.net/\\n\\nHRM system\\nAPI DOCUMENTATION\\nEndpoints:\\n- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\\n- /api/User/me/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/me/<email>: accepts an EMAIL string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/manager-users: Use GET with this endpoint to get name of a manager user.\\n- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\\n\" question_key='question' output_key='output'\n"
     ]
    }
   ],
   "source": [
    "print(chain_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2962f4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mhttps://hrm-nois-fake.azurewebsites.net/api/User\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{\"message\":\"OK\",\"data\":[{\"id\":\"262aa143-307a-4b9f-848d-1e6bf2e5cacb\",\"name\":\"Hung Bui\",\"email\":\"hung.bui@nois.vn\",\"fullName\":\"BÙI TUẤN HƯNG\",\"jobTitle\":\"Lập trình viên\",\"mobilePhone\":\"0966772170\",\"birthday\":\"1997-08-17T00:00:00\",\"offDay\":0.5,\"yearOffDay\":6,\"maxDayOff\":15,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":1,\"gender\":1,\"personalEmail\":\"hungbt.dev@gmail.com\",\"avatar\":\"https://noishrm.blob.core.windows.net/avatar/8fec9283-e82f-43ec-8f61-addb732dabcb.jpeg\",\"acceptOfferDate\":\"2022-10-31T00:00:00\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"Development Unit 1\",\"groupUserId\":\"\",\"groupUserName\":\"Nhân viên chính thức\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"2021-08-10T00:00:00\",\"issuedBy\":\"Cục trưởng CCS QLHC về TTXH\",\"placeOfTemporaryResidence\":\"502/15/2 Thống Nhất, p.16, Gò Vấp, TP.HCM\",\"placeOfResidence\":\"161 Đường 458, Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM\",\"relativeName\":\"Lê Thị Kiều\",\"relationship\":\"Mẹ\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"Vietcombank\",\"bankBranch\":\"DONG SAI GON-PGD THANH DA\",\"bankAccountNumber\":\"0531002579897\",\"birthPlace\":\"Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"8460719408\",\"education\":\"\",\"jobId\":\"\",\"jobName\":\"Developer\",\"levelId\":\"\",\"levelName\":\"\"},{\"id\":\"65255df1-d4c3-479b-a4b8-d63cb3db2beb\",\"name\":\"Nghiem Vo\",\"email\":\"nghiem.vo@nois.vn\",\"fullName\":\"VÕ NGỌC DUY NGHIÊM\",\"jobTitle\":\"Lập trình viên\",\"mobilePhone\":\"0843961713\",\"birthday\":\"1999\",\"offDay\":1,\"yearOffDay\":0,\"maxDayOff\":10,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":0,\"gender\":0,\"personalEmail\":\"\",\"avatar\":\"\",\"acceptOfferDate\":\"\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"Development Unit 1\",\"groupUserId\":\"\",\"groupUserName\":\"\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"\",\"issuedBy\":\"\",\"placeOfTemporaryResidence\":\"\",\"placeOfResidence\":\"\",\"relativeName\":\"\",\"relationship\":\"\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"VIB\",\"bankBranch\":\"\",\"bankAccountNumber\":\"863644436\",\"birthPlace\":\"Los Angeles\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"\",\"education\":\"Bach Khoa University\",\"jobId\":\"\",\"jobName\":\"chatbot\",\"levelId\":\"\",\"levelName\":\"Internship\"},{\"id\":\"c8604118-7db6-4e08-8926-5bd8c81bce81\",\"name\":\"Bao Ho\",\"email\":\"honguyenngocbao@gmail.com\",\"fullName\":\"HỒ NGUYỄN NGỌC BẢO\",\"jobTitle\":\"\",\"mobilePhone\":\"\",\"birthday\":\"\",\"offDay\":1.5,\"yearOffDay\":0,\"maxDayOff\":0,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":0,\"gender\":0,\"personalEmail\":\"\",\"avatar\":\"\",\"acceptOfferDate\":\"\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"\",\"groupUserId\":\"\",\"groupUserName\":\"\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"\",\"issuedBy\":\"\",\"placeOfTemporaryResidence\":\"\",\"placeOfResidence\":\"\",\"relativeName\":\"\",\"relationship\":\"\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"\",\"bankBranch\":\"\",\"bankAccountNumber\":\"\",\"birthPlace\":\"\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"\",\"education\":\"\",\"jobId\":\"\",\"jobName\":\"\",\"levelId\":\"\",\"levelName\":\"\"}]}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"Users's birthday'?\",\n",
       " 'output': \"The response contains a list of users within the HRM system. Each user has various details, including their ID, name, email, job title, mobile phone, birthday, and other personal information. However, the specific user's birthday is not provided in the response.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new(\"Users's birthday'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b1d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://hrm-nois-fake.azurewebsites.net/\"\n",
    "date = str(datetime.now().date())\n",
    "email = 'bao.ho@nois.vn'\n",
    "\n",
    "def get_users(query: str = None):\n",
    "    return requests.get(url + '/api/User').json()['data']\n",
    "\n",
    "def delAll(ID: str):\n",
    "    lst = []\n",
    "    get_reply = requests.get(url + f\"/api/LeaveApplication/{ID}\").json()\n",
    "    for i in get_reply['data']:\n",
    "        lst.append(i['id'])\n",
    "        \n",
    "    for i in lst:\n",
    "        del_reply = requests.delete(url + f\"/api/LeaveApplication/{i}\")\n",
    "        print(del_reply.text)\n",
    "\n",
    "def get_user_by_email(query: str = None):\n",
    "    response = requests.get(url + f'/api/User/me?email={email}')\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['data']\n",
    "    \n",
    "    return f'Error: {response.status_code}'\n",
    "\n",
    "def get_user_by_id(ID: str):\n",
    "    reply = requests.get(url + f'/api/User/me?id={ID}')\n",
    "    if response.status_code != 200:\n",
    "        return f'Error: {response.status_code}'\n",
    "    \n",
    "    if not reply.json()['data']:\n",
    "        return \"Wrong ID, recheck your input.\"\n",
    "    \n",
    "    return reply.json()['data']\n",
    "\n",
    "def check_manager_name(name):\n",
    "    response = requests.get(url + '/api/User/manager-users').json()['data']\n",
    "    \n",
    "    for data in response:\n",
    "        if data['fullName'].lower() == name.lower(): \n",
    "            return data['id']\n",
    "        \n",
    "    return -1\n",
    "def check_manager_id(managerId):\n",
    "    response = requests.get(url + '/api/User/manager-users').json()['data']\n",
    "    \n",
    "    for data in response:\n",
    "        if data['id'] == int(managerId): \n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "    \n",
    "def post_method(user_id, manager_id, start_date, end_date):\n",
    "    start_datetime = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_datetime = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    num_days = 0\n",
    "    \n",
    "    if end_datetime == start_datetime:\n",
    "        num_days = 0.5\n",
    "    else:\n",
    "        num_days = (end_datetime - start_datetime).days\n",
    "        \n",
    "    response = requests.post('https://hrm-nois-fake.azurewebsites.net/api/LeaveApplication/Submit', json = {\n",
    "        \"userId\": user_id,\n",
    "        \"reviewUserId\": manager_id,\n",
    "        \"relatedUserId\": \"string\",\n",
    "        \"fromDate\": start_date,\n",
    "        \"toDate\": end_date,\n",
    "        \"leaveApplicationTypeId\": 0,\n",
    "        \"leaveApplicationNote\": \"string\",\n",
    "        \"periodType\": 0,\n",
    "        \"numberOffDay\": num_days\n",
    "    })\n",
    "    \n",
    "    return response\n",
    "    \n",
    "lst = []\n",
    "def submitLeaveApplication(args: str):\n",
    "    global lst\n",
    "    lst = args.split(', ')\n",
    "    \n",
    "    if len(lst) != 4:\n",
    "        return \"Incorrect number of arguments, this function requires 4 arguments: user's id, manager's id, start date and end date.\"\n",
    "    \n",
    "    \n",
    "    if '-' not in lst[0]:\n",
    "        '''\"Incorrect ID. You can find the correct ID by using the HRM get by email tool.\"'''\n",
    "        return \"Get user ID by using the tool HRM get user info\"\n",
    "    \n",
    "    if check_manager_name(lst[1]) == -1 and check_manager_id(lst[1]) == False:\n",
    "        return \"Ask the user for the correct manager's name. The user either didn't give you a name or gave you the wrong name.\"\n",
    "    \n",
    "    if '-' not in lst[2]:\n",
    "        return \"Ask the user when they want to start their leave. Infer the date based on the user's answer.\"\n",
    "    \n",
    "    if datetime.strptime(lst[2], \"%Y-%m-%d\") < datetime.strptime(date, \"%Y-%m-%d\"):\n",
    "        return \"Start date cannot be earlier than current date, ask the user for another date.\"\n",
    "    \n",
    "    if '-' not in lst[3]:\n",
    "        return \"Ask the user when they want to end their leave. Infer the date based on the user's answer.\"\n",
    "    \n",
    "    if datetime.strptime(lst[3], \"%Y-%m-%d\") < datetime.strptime(lst[2], \"%Y-%m-%d\"):\n",
    "        return \"End date cannot be earlier than start date, ask the user for another date.\"\n",
    "    \n",
    "    print(\"\\nUserId: \", lst[0])\n",
    "    print(\"ReviewerId: \", lst[1])\n",
    "    print(\"Start date: \", lst[2])\n",
    "    print(\"End date: \", lst[3])\n",
    "    \n",
    "    reply = post_method(lst[0], int(lst[1]), lst[2], lst[3])\n",
    "    \n",
    "#     return reply.text\n",
    "    return 'success'\n",
    "        \n",
    "tools = [    \n",
    "    \n",
    "    Tool(\n",
    "        name='HRM get by name',\n",
    "        func=check_manager_name,\n",
    "        description='useful for getting the manager\\'s id by manager\\'s name. Input is a manager\\'s name.'\n",
    "    ),\n",
    "    \n",
    "#     Tool(\n",
    "#         name='HRM get by email',\n",
    "#         func=get_user_by_email,\n",
    "#         description='useful for getting the user\\'s id by user\\'s email.'\n",
    "#     ),\n",
    "    \n",
    "    Tool(\n",
    "        name='HRM get user info',\n",
    "        func=get_user_by_email,\n",
    "        description='useful for getting personal information of the user chatting with you. No input neccessary.'\n",
    "    ),\n",
    "    \n",
    "    Tool(\n",
    "        name='HRM submit leave',\n",
    "        func=submitLeaveApplication,\n",
    "        description=f'''useful for submitting leave applications for a specific user.\n",
    "Input must include 4 parameters concatenated into a string separated by a comma and space, which are: \n",
    "1. user's id: you get by using the tool HRM get user info.\n",
    "2. manager's id: firstly, ask user the name of the manager and then find manager's id by name.\n",
    "3. start date: ask the user when they want to start their leave.\n",
    "4. end date: ask the user when they want to end their leave.\n",
    "Default input form is: [user's id], [manager's id], [start date], [end date]\n",
    "'''\n",
    "    )\n",
    "]\n",
    "\n",
    "# Example: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, LÝ MINH QUÂN, 2023-07-10, 2023-07-11\n",
    "\n",
    "human = load_tools(['human'])\n",
    "\n",
    "tools.extend(human)\n",
    "\n",
    "f'''If you cannot answer by using only 1 tool, try using other provided tools.\n",
    "If you cannot get any results from tools, say you don't know.\n",
    "Do not use any other sources other than the ones you obtain from tools.'''\n",
    "\n",
    "prefix = f\"\"\"You are an intelligent assistant helping users interact with system called HRM through the use of tools.\n",
    "Answer in the user's language.\n",
    "The user chatting with you has the email {email}. Suppose the current date is {date} (Year-Month-Day).\n",
    "You have access to the following tools:\"\"\"\n",
    "\n",
    "'''\n",
    "\n",
    "Examples: \n",
    "\n",
    "Thought: find the user's id by user's email.\n",
    "Action: HRM get by email\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, [manager's id], [start date], [end date]\n",
    "Thought: Ask the user for the manager's name.\n",
    "Action: human\n",
    "Action Input: What is the name of the manager who will approve your application?\n",
    "Thought: find the manager's id by manager's name.\n",
    "Action: HRM get by name\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, 139, [start date], [end date]\n",
    "Thought: ask user the date of starting leaving (according the format Year-Month-Day)?\n",
    "Action: human\n",
    "Action Input: When do you want to start your leave? (I'm currently using Year-Month-Day format)\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb , 139, 2023-07-17, [end date]\n",
    "Thought: ask user the date of ending leaving (according the format Year-Month-Day)?\n",
    "Action: human\n",
    "Action Input: When do you want to end your leave? (I'm currently using Year-Month-Day format)\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb , 139, 2023-07-17, 2023-07-18\n",
    "Thought: I have all the details from the user, I will now submit the application.\n",
    "Action: HRM submit leave\n",
    "Observation: success\n",
    "Thought: The leave application was submitted successfully.\n",
    "Final Answer: The leave application was submitted successfully.'''\n",
    "\n",
    "suffix = \"\"\"Begin!\n",
    "\n",
    "{context}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"context\", \"agent_scratchpad\"],\n",
    ")\n",
    "\n",
    "history = ConversationBufferWindowMemory(k=3, memory_key=\"context\", human_prefix='User', ai_prefix='Assistant', return_messages=True)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm3, prompt=prompt)\n",
    "\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True, stop=[\"\\nObservation:\", \"<|im_end|>\", \"<|im_sep|>\"])\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools, \n",
    "    verbose=True,\n",
    "    handle_parsing_errors=\"True\",\n",
    "    memory=history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a6d3ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: First, we need to get the user's id and the name of their manager.\n",
      "Action: HRM get user info\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{'id': 'd5415e70-eb99-4536-a649-777efd829e07', 'name': 'Bao Ho', 'email': 'bao.ho@nois.vn', 'fullName': 'HỒ NGUYỄN NGỌC BẢO', 'jobTitle': 'Lập Trình Viên', 'mobilePhone': '', 'birthday': '2002-04-30', 'offDay': 11, 'yearOffDay': 0, 'maxDayOff': 0, 'remainDayOffLastYear': 0, 'offDayUseRamainDayOffLastYear': 0, 'gender': 1, 'personalEmail': 'honguyenngocbao@gmail.com', 'avatar': '', 'acceptOfferDate': '', 'quitJobDate': '', 'bonusDayOff': 0, 'managerId': '139', 'managerFullName': 'LÝ MINH QUÂN', 'departmentId': 0, 'departmentName': '', 'groupUserId': '', 'groupUserName': '', 'hasLeft': '', 'identityCard': '', 'dateOfIssue': '', 'issuedBy': '', 'placeOfTemporaryResidence': '', 'placeOfResidence': '', 'relativeName': '', 'relationship': '', 'relativeMobilePhone': '', 'hasBankAccount': '', 'bankName': '', 'bankBranch': '', 'bankAccountNumber': '', 'birthPlace': '', 'isFirstLogin': '', 'roles': '', 'taxIdentificationNumber': '', 'education': '', 'jobId': '', 'jobName': '', 'levelId': '', 'levelName': ''}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe have the user's id: d5415e70-eb99-4536-a649-777efd829e07. Now we need to get the manager's id.\n",
      "Action: HRM get by name\n",
      "Action Input: \"What is the name of your manager?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m-1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe manager's name is not provided. We need to ask the user for their manager's name.\n",
      "Action: human\n",
      "Action Input: \"What is the name of your manager?\"\u001b[0m\n",
      "\n",
      "What is the name of your manager?\n",
      "lý minh quân\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mlý minh quân\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow we have the manager's name: Lý Minh Quân. Let's use the HRM get by name tool to get their id.\n",
      "Action: HRM get by name\n",
      "Action Input: \"Lý Minh Quân\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m139\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe now have the user's id and their manager's id. Now we need to get the start and end dates for the leave application.\n",
      "Action: human\n",
      "Action Input: \"When do you want to start your leave? Please enter in the format YYYY-MM-DD.\"\u001b[0m\n",
      "\n",
      "When do you want to start your leave? Please enter in the format YYYY-MM-DD.\n",
      "2023-07-19\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m2023-07-19\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe have the start date: 2023-07-19. Now we need to get the end date.\n",
      "Action: human\n",
      "Action Input: \"When do you want to end your leave? Please enter in the format YYYY-MM-DD.\"\u001b[0m\n",
      "\n",
      "When do you want to end your leave? Please enter in the format YYYY-MM-DD.\n",
      "2023-07-20\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m2023-07-20\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe have the end date: 2023-07-20. Now we can use the HRM submit leave tool to submit the leave application.\n",
      "Action: HRM submit leave\n",
      "Action Input: \"d5415e70-eb99-4536-a649-777efd829e07, 139, 2023-07-19, 2023-07-20\"\u001b[0m\n",
      "UserId:  d5415e70-eb99-4536-a649-777efd829e07\n",
      "ReviewerId:  139\n",
      "Start date:  2023-07-19\n",
      "End date:  2023-07-20\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3msuccess\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe leave application has been successfully submitted.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:'\n",
      "Thought:\u001b[32;1m\u001b[1;3mOops, I made a mistake. Let me correct it.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:'\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to provide the final answer to the original input question.\n",
      "Final Answer: To submit a leave application, please provide your user id, manager's name, start date, and end date. You can use the HRM get user info and HRM get by name tools to get the necessary information, and the HRM submit leave tool to submit the application.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "history.clear()\n",
    "answer = agent_chain.run(input=\"I'd like to submit a leave application.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9312dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To submit a leave application, please provide your user id, manager's name, start date, and end date. You can use the HRM get user info and HRM get by name tools to get the necessary information, and the HRM submit leave tool to submit the application.\n",
      "['d5415e70-eb99-4536-a649-777efd829e07', '139', '2023-07-19', '2023-07-20']\n"
     ]
    }
   ],
   "source": [
    "print(answer)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b293b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"OK\",\"data\":\"success\"}\n",
      "{\"message\":\"OK\",\"data\":\"success\"}\n",
      "{\"message\":\"OK\",\"data\":\"success\"}\n",
      "{\"message\":\"OK\",\"data\":\"success\"}\n"
     ]
    }
   ],
   "source": [
    "delAll(\"d5415e70-eb99-4536-a649-777efd829e07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b48ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"OK\"}\n"
     ]
    }
   ],
   "source": [
    "new_user = {\n",
    "    \"name\": \"Bao Ho\",\n",
    "    \"email\": \"bao.ho@nois.vn\",\n",
    "    \"fullName\": \"HỒ NGUYỄN NGỌC BẢO\",\n",
    "    \"jobTitle\": \"Lập Trình Viên\",\n",
    "    \"birthday\": \"2002-04-30\",\n",
    "    \"gender\": 1,\n",
    "    \"personalEmail\": \"honguyenngocbao@gmail.com\",\n",
    "    \"managerId\": '139',\n",
    "    \"managerFullName\": \"LÝ MINH QUÂN\",\n",
    "}\n",
    "\n",
    "reply = requests.post(url + 'api/User', json = new_user)\n",
    "print(reply.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2242ad81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
