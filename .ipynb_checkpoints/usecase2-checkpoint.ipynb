{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb122fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains import LLMChain, APIChain\n",
    "from langchain.chains.api.prompt import API_RESPONSE_PROMPT\n",
    "from langchain.schema import Document\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import ZeroShotAgent, AgentExecutor, AgentType, initialize_agent, Tool, load_tools\n",
    "from langchain.agents.agent_toolkits.openapi import planner\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.api import open_meteo_docs\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_endpoint = 'https://search-service01.search.windows.net'\n",
    "search_key = '73Swa5YqUR5IRMwUIqOH6ww2YBm3SveLv7rDmZVXtIAzSeBjEQe9'\n",
    "private_index_name = \"nois-private-v3-index\"\n",
    "\n",
    "retriever_private = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=private_index_name,\n",
    "    credential=AzureKeyCredential(search_key),\n",
    "    b=0.0,\n",
    "    k1=0.3,\n",
    "    searchMode=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8b195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "def count_tokens(s):\n",
    "    return len(enc.encode(s))\n",
    "string = '''User info:\n",
    "id: d5415e70-eb99-4536-a649-777efd829e07\n",
    "name: Bao Ho\n",
    "email: bao.ho@nois.vn\n",
    "fullName: HỒ NGUYỄN NGỌC BẢO\n",
    "jobTitle: Lập Trình Viên\n",
    "mobilePhone: \n",
    "birthday: 2002-04-30\n",
    "offDay: 1\n",
    "yearOffDay: 0\n",
    "maxDayOff: 0\n",
    "remainDayOffLastYear: 0\n",
    "offDayUseRamainDayOffLastYear: 0\n",
    "gender: 1\n",
    "personalEmail: honguyenngocbao@gmail.com\n",
    "avatar: \n",
    "acceptOfferDate: \n",
    "quitJobDate: \n",
    "bonusDayOff: 0\n",
    "managerId: 139\n",
    "managerFullName: LÝ MINH QUÂN\n",
    "departmentId: 0\n",
    "departmentName: \n",
    "groupUserId: \n",
    "groupUserName: \n",
    "hasLeft: \n",
    "identityCard: \n",
    "dateOfIssue: \n",
    "issuedBy: \n",
    "placeOfTemporaryResidence: \n",
    "placeOfResidence: \n",
    "relativeName: \n",
    "relationship: \n",
    "relativeMobilePhone: \n",
    "hasBankAccount: \n",
    "bankName: \n",
    "bankBranch: \n",
    "bankAccountNumber: \n",
    "birthPlace: \n",
    "isFirstLogin: \n",
    "roles: \n",
    "taxIdentificationNumber: \n",
    "education: \n",
    "jobId: \n",
    "jobName: \n",
    "levelId: \n",
    "levelName: \n",
    "'''\n",
    "print(count_tokens(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde3db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transferred to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache=None verbose=False callbacks=None callback_manager=None tags=None metadata=None client=<class 'openai.api_resources.chat_completion.ChatCompletion'> model_name='gpt-3.5-turbo' temperature=0.0 model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']} openai_api_key='400568d9a16740b88aff437480544a39' openai_api_base='https://openai-nois-intern.openai.azure.com/' openai_organization='' openai_proxy='' request_timeout=None max_retries=6 streaming=False n=1 max_tokens=600 tiktoken_model_name=None deployment_name='gpt-35-turbo' openai_api_type='azure' openai_api_version='2023-03-15-preview'\n",
      "761\n"
     ]
    }
   ],
   "source": [
    "# Load up your LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0.5,\n",
    "    max_tokens=450\n",
    ")\n",
    "\n",
    "llm2 = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0,\n",
    "    max_tokens=600,\n",
    "    stop=['\\n', '<|im_end|>', '<|im_sep|>']\n",
    ")\n",
    "\n",
    "llm3 = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_base='https://openai-nois-intern.openai.azure.com/',\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    deployment_name='gpt-35-turbo',\n",
    "    openai_api_key='400568d9a16740b88aff437480544a39',\n",
    "    temperature=0.0,\n",
    "    max_tokens=600\n",
    ")\n",
    "\n",
    "history = []\n",
    "history_entry = 1\n",
    "\n",
    "def get_history_as_txt():\n",
    "    txt = \"\"\n",
    "    hist = history[::-1]\n",
    "    \n",
    "    for i in hist[:3]:\n",
    "        txt += f\"\\n<|im_start|>user\\n{i['user']}\\n<|im_end|>\\n\"\n",
    "        txt += f\"<|im_start|>assistant\\n{i['AI']}\\n<|im_end|>\"\n",
    "        \n",
    "    return txt\n",
    "\n",
    "def add_to_history(user_msg, ai_msg):\n",
    "    history.append({'user': user_msg, 'AI': ai_msg})\n",
    "    \n",
    "def save_history_to_file():\n",
    "    global history_entry\n",
    "    file = open(f\"chatbot-cases/chat-{history_entry}.txt\", 'w', encoding='utf-8')\n",
    "    file.write(get_history_as_txt())\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    history_entry += 1\n",
    "    \n",
    "def doc_to_str(doc):\n",
    "    string = \"\"\n",
    "    for i in doc:\n",
    "        string += i.page_content\n",
    "        \n",
    "    return string\n",
    "\n",
    "print(llm2)\n",
    "doc = open_meteo_docs.OPEN_METEO_DOCS\n",
    "print(llm2.get_num_tokens(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440dbba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE URL: https://hrm-nois-fake.azurewebsites.net/\n",
      "\n",
      "HRM system\n",
      "API DOCUMENTATION\n",
      "Endpoints:\n",
      "- /api/User/me?email=<email>: accepts an email as input. Use GET with this endpoint along with a user's email to get data of a specific user.\n",
      "- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\n",
      "API token length: 100\n"
     ]
    }
   ],
   "source": [
    "# print(open_meteo_docs.OPEN_METEO_DOCS)\n",
    "hrm_doc = open(\"HRM_API_DOC.txt\", 'r', encoding='utf-8')\n",
    "api_doc = hrm_doc.read()\n",
    "print(api_doc)\n",
    "print(f\"API token length: {count_tokens(api_doc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b02489",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_new = APIChain.from_llm_and_api_docs(llm2, api_doc, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e00702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lc_kwargs={'api_request_chain': LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text'), 'api_answer_chain': LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text'), 'requests_wrapper': TextRequestsWrapper(headers=None, aiosession=None), 'api_docs': \"BASE URL: https://hrm-nois-fake.azurewebsites.net/\\n\\nHRM system\\nAPI DOCUMENTATION\\nEndpoints:\\n- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\\n- /api/User/me/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/me/<email>: accepts an EMAIL string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/manager-users: Use GET with this endpoint to get name of a manager user.\\n- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\\n\", 'verbose': True} memory=None callbacks=None callback_manager=None verbose=True api_request_chain=LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:'}, input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text') api_answer_chain=LLMChain(lc_kwargs={'llm': AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), 'prompt': PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True)}, memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(lc_kwargs={'input_variables': ['api_docs', 'question', 'api_url', 'api_response'], 'template': 'You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:'}, input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(lc_kwargs={'openai_api_type': 'azure', 'openai_api_base': 'https://openai-nois-intern.openai.azure.com/', 'openai_api_version': '2023-03-15-preview', 'deployment_name': 'gpt-35-turbo', 'openai_api_key': '400568d9a16740b88aff437480544a39', 'temperature': 0, 'max_tokens': 600, 'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={'stop': ['\\n', '<|im_end|>', '<|im_sep|>']}, openai_api_key='400568d9a16740b88aff437480544a39', openai_api_base='https://openai-nois-intern.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=600, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-03-15-preview'), output_key='text') requests_wrapper=TextRequestsWrapper(headers=None, aiosession=None) api_docs=\"BASE URL: https://hrm-nois-fake.azurewebsites.net/\\n\\nHRM system\\nAPI DOCUMENTATION\\nEndpoints:\\n- /api/User: does not accept any input. Use GET with this endpoint to get a list of users within the HRM system.\\n- /api/User/me/<id>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/me/<email>: accepts an EMAIL string as a path variable. Use GET with this endpoint along with a user's ID to get data of a specific user.\\n- /api/User/manager-users: Use GET with this endpoint to get name of a manager user.\\n- /api/LeaveApplication/<userId>: accepts an ID string as a path variable. Use GET with this endpoint along with a user's ID to get all leave applications submitted by a user.\\n\" question_key='question' output_key='output'\n"
     ]
    }
   ],
   "source": [
    "print(chain_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2962f4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in on_chain_start callback: 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mhttps://hrm-nois-fake.azurewebsites.net/api/User\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m{\"message\":\"OK\",\"data\":[{\"id\":\"262aa143-307a-4b9f-848d-1e6bf2e5cacb\",\"name\":\"Hung Bui\",\"email\":\"hung.bui@nois.vn\",\"fullName\":\"BÙI TUẤN HƯNG\",\"jobTitle\":\"Lập trình viên\",\"mobilePhone\":\"0966772170\",\"birthday\":\"1997-08-17T00:00:00\",\"offDay\":0.5,\"yearOffDay\":6,\"maxDayOff\":15,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":1,\"gender\":1,\"personalEmail\":\"hungbt.dev@gmail.com\",\"avatar\":\"https://noishrm.blob.core.windows.net/avatar/8fec9283-e82f-43ec-8f61-addb732dabcb.jpeg\",\"acceptOfferDate\":\"2022-10-31T00:00:00\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"Development Unit 1\",\"groupUserId\":\"\",\"groupUserName\":\"Nhân viên chính thức\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"2021-08-10T00:00:00\",\"issuedBy\":\"Cục trưởng CCS QLHC về TTXH\",\"placeOfTemporaryResidence\":\"502/15/2 Thống Nhất, p.16, Gò Vấp, TP.HCM\",\"placeOfResidence\":\"161 Đường 458, Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM\",\"relativeName\":\"Lê Thị Kiều\",\"relationship\":\"Mẹ\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"Vietcombank\",\"bankBranch\":\"DONG SAI GON-PGD THANH DA\",\"bankAccountNumber\":\"0531002579897\",\"birthPlace\":\"Ấp Hội Thạnh, Xã Trung An, Huyện Củ Chi, TP.HCM\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"8460719408\",\"education\":\"\",\"jobId\":\"\",\"jobName\":\"Developer\",\"levelId\":\"\",\"levelName\":\"\"},{\"id\":\"65255df1-d4c3-479b-a4b8-d63cb3db2beb\",\"name\":\"Nghiem Vo\",\"email\":\"nghiem.vo@nois.vn\",\"fullName\":\"VÕ NGỌC DUY NGHIÊM\",\"jobTitle\":\"Lập trình viên\",\"mobilePhone\":\"0843961713\",\"birthday\":\"1999\",\"offDay\":1,\"yearOffDay\":0,\"maxDayOff\":10,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":0,\"gender\":0,\"personalEmail\":\"\",\"avatar\":\"\",\"acceptOfferDate\":\"\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"Development Unit 1\",\"groupUserId\":\"\",\"groupUserName\":\"\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"\",\"issuedBy\":\"\",\"placeOfTemporaryResidence\":\"\",\"placeOfResidence\":\"\",\"relativeName\":\"\",\"relationship\":\"\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"VIB\",\"bankBranch\":\"\",\"bankAccountNumber\":\"863644436\",\"birthPlace\":\"Los Angeles\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"\",\"education\":\"Bach Khoa University\",\"jobId\":\"\",\"jobName\":\"chatbot\",\"levelId\":\"\",\"levelName\":\"Internship\"},{\"id\":\"c8604118-7db6-4e08-8926-5bd8c81bce81\",\"name\":\"Bao Ho\",\"email\":\"honguyenngocbao@gmail.com\",\"fullName\":\"HỒ NGUYỄN NGỌC BẢO\",\"jobTitle\":\"\",\"mobilePhone\":\"\",\"birthday\":\"\",\"offDay\":1.5,\"yearOffDay\":0,\"maxDayOff\":0,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":0,\"gender\":0,\"personalEmail\":\"\",\"avatar\":\"\",\"acceptOfferDate\":\"\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"\",\"managerFullName\":\"\",\"departmentId\":0,\"departmentName\":\"\",\"groupUserId\":\"\",\"groupUserName\":\"\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"\",\"issuedBy\":\"\",\"placeOfTemporaryResidence\":\"\",\"placeOfResidence\":\"\",\"relativeName\":\"\",\"relationship\":\"\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"\",\"bankBranch\":\"\",\"bankAccountNumber\":\"\",\"birthPlace\":\"\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"\",\"education\":\"\",\"jobId\":\"\",\"jobName\":\"\",\"levelId\":\"\",\"levelName\":\"\"}]}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"Users's birthday'?\",\n",
       " 'output': \"The response contains a list of users within the HRM system. Each user has various details, including their ID, name, email, job title, mobile phone, birthday, and other personal information. However, the specific user's birthday is not provided in the response.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_new(\"Users's birthday'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78b1d4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday 2023-07-13\n"
     ]
    }
   ],
   "source": [
    "url = \"https://hrm-nois-fake.azurewebsites.net/\"\n",
    "date = datetime.strftime(datetime.today().date(), \"%A %Y-%m-%d\")\n",
    "print(date)\n",
    "email = 'bao.ho@nois.vn'\n",
    "\n",
    "def get_users(query: str = None):\n",
    "    return requests.get(url + '/api/User').json()['data']\n",
    "\n",
    "def delAll(ID: str):\n",
    "    lst = []\n",
    "    get_reply = requests.get(url + f\"/api/LeaveApplication/{ID}\").json()\n",
    "    for i in get_reply['data']:\n",
    "        lst.append(i['id'])\n",
    "        \n",
    "    for i in lst:\n",
    "        del_reply = requests.delete(url + f\"/api/LeaveApplication/{i}\")\n",
    "        print(del_reply.text)\n",
    "\n",
    "def get_user_by_email(query: str = None):\n",
    "    response = requests.get(url + f'/api/User/me?email={email}')\n",
    "    if response.status_code == 200:\n",
    "        return_text = \"User info:\\n\"\n",
    "        user_data = response.json()['data']\n",
    "        \n",
    "        for i in user_data.items():\n",
    "            return_text += f\"{i[0]}: {i[1]}\\n\"\n",
    "            if i[0] == \"maxDayOff\":\n",
    "                return_text += f\"remainingOffDays: {user_data['maxDayOff'] - user_data['offDay']}\\n\"\n",
    "            \n",
    "        return return_text\n",
    "    \n",
    "    return f'Error: {response.status_code}'\n",
    "\n",
    "def get_user_by_id(ID: str):\n",
    "    reply = requests.get(url + f'/api/User/me?id={ID}')\n",
    "    if response.status_code != 200:\n",
    "        return f'Error: {response.status_code}'\n",
    "    \n",
    "    if not reply.json()['data']:\n",
    "        return \"Wrong ID, recheck your input.\"\n",
    "    \n",
    "    return reply.json()['data']\n",
    "\n",
    "def check_manager_name(name):\n",
    "    response = requests.get(url + '/api/User/manager-users').json()['data']\n",
    "    \n",
    "    for data in response:\n",
    "        if data['fullName'].lower() == name.lower(): \n",
    "            return data['id']\n",
    "        \n",
    "    return -1\n",
    "def check_manager_id(managerId):\n",
    "    response = requests.get(url + '/api/User/manager-users').json()['data']\n",
    "    \n",
    "    for data in response:\n",
    "        if data['id'] == int(managerId): \n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "    \n",
    "def post_method(user_id, manager_id, start_date, end_date):\n",
    "    start_datetime = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_datetime = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    \n",
    "    num_days = 0\n",
    "    \n",
    "    if end_datetime == start_datetime:\n",
    "        num_days = 0.5\n",
    "    else:\n",
    "        num_days = (end_datetime - start_datetime).days\n",
    "        \n",
    "    response = requests.post('https://hrm-nois-fake.azurewebsites.net/api/LeaveApplication/Submit', json = {\n",
    "        \"userId\": user_id,\n",
    "        \"reviewUserId\": manager_id,\n",
    "        \"relatedUserId\": \"string\",\n",
    "        \"fromDate\": start_date,\n",
    "        \"toDate\": end_date,\n",
    "        \"leaveApplicationTypeId\": 0,\n",
    "        \"leaveApplicationNote\": \"string\",\n",
    "        \"periodType\": 0,\n",
    "        \"numberOffDay\": num_days\n",
    "    })\n",
    "    \n",
    "    return response\n",
    "    \n",
    "lst = []\n",
    "def submitLeaveApplication(args: str):\n",
    "    global lst\n",
    "    lst = args.split(', ')\n",
    "    \n",
    "    if len(lst) != 4:\n",
    "        return \"Incorrect number of arguments, this function requires 4 arguments: user's id, manager's id, start date and end date.\"\n",
    "    \n",
    "    \n",
    "    if '-' not in lst[0]:\n",
    "        '''\"Incorrect ID. You can find the correct ID by using the HRM get by email tool.\"'''\n",
    "        return \"Get user ID by using the tool HRM get user info\"\n",
    "    \n",
    "    if check_manager_name(lst[1]) == -1 and check_manager_id(lst[1]) == False:\n",
    "        return \"Ask the user for the correct manager's name. The user either didn't give you a name or gave you the wrong name.\"\n",
    "    \n",
    "    if '-' not in lst[2]:\n",
    "        return \"Ask the user when they want to start their leave. Infer the date based on the user's answer.\"\n",
    "    \n",
    "    if datetime.strptime(lst[2], \"%Y-%m-%d\") < datetime.strptime(date, \"%Y-%m-%d\"):\n",
    "        return \"Start date cannot be earlier than current date, ask the user for another date.\"\n",
    "    \n",
    "    if '-' not in lst[3]:\n",
    "        return \"Ask the user when they want to end their leave. Infer the date based on the user's answer.\"\n",
    "    \n",
    "    if datetime.strptime(lst[3], \"%Y-%m-%d\") < datetime.strptime(lst[2], \"%Y-%m-%d\"):\n",
    "        return \"End date cannot be earlier than start date, ask the user for another date.\"\n",
    "    \n",
    "    print(\"\\nUserId: \", lst[0])\n",
    "    print(\"ReviewerId: \", lst[1])\n",
    "    print(\"Start date: \", lst[2])\n",
    "    print(\"End date: \", lst[3])\n",
    "    \n",
    "    reply = post_method(lst[0], int(lst[1]), lst[2], lst[3])\n",
    "    \n",
    "#     return reply.text\n",
    "    return 'success'\n",
    "        \n",
    "tools = [    \n",
    "    \n",
    "    Tool(\n",
    "        name='HRM get manager id',\n",
    "        func=check_manager_name,\n",
    "        description=\"useful for getting the manager\\'s id using manager\\'s name. Input is a manager\\'s name and nothing else.\"\n",
    "    ),\n",
    "    \n",
    "#     Tool(\n",
    "#         name='HRM get by email',\n",
    "#         func=get_user_by_email,\n",
    "#         description='useful for getting the user\\'s id by user\\'s email.'\n",
    "#     ),\n",
    "    \n",
    "    Tool(\n",
    "        name='HRM get user info',\n",
    "        func=get_user_by_email,\n",
    "        description='useful for getting personal information of the user chatting with you. No input neccessary.'\n",
    "    ),\n",
    "    \n",
    "    Tool(\n",
    "        name='HRM submit leave',\n",
    "        func=submitLeaveApplication,\n",
    "        description=f'''useful for submitting leave applications for a specific user.\n",
    "Input must include 4 parameters concatenated into a string separated by a comma and space, which are: \n",
    "1. user's id: you get by using the tool HRM get user info.\n",
    "2. manager's id: ask the user for the manager's name, and find the manager's id using the tool HRM get manager id.\n",
    "3. start date: ask the user when they want to start their leave. Date format is YYYY-MM-DD.\n",
    "4. end date: ask the user when they want to end their leave. Date format is YYYY-MM-DD.\n",
    "Default input form is: [user's id], [manager's id], [start date], [end date]\n",
    "'''\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Example: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, LÝ MINH QUÂN, 2023-07-10, 2023-07-11\n",
    "\n",
    "human = load_tools(['human'])\n",
    "\n",
    "tools.extend(human)\n",
    "\n",
    "f'''If you cannot answer by using only 1 tool, try using other provided tools.\n",
    "If you cannot get any results from tools, say you don't know.\n",
    "Do not use any other sources other than the ones you obtain from tools.'''\n",
    "\n",
    "prefix = f\"\"\"You are an intelligent assistant helping users interact with system called HRM through the use of tools.\n",
    "Answer in the user's language.\n",
    "The user chatting with you has the email {email}. Suppose the current date is {date} (Weekday YYYY-MM-DD).\n",
    "You have access to the following tools:\"\"\"\n",
    "\n",
    "'''\n",
    "\n",
    "Examples: \n",
    "\n",
    "Thought: find the user's id by user's email.\n",
    "Action: HRM get by email\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, [manager's id], [start date], [end date]\n",
    "Thought: Ask the user for the manager's name.\n",
    "Action: human\n",
    "Action Input: What is the name of the manager who will approve your application?\n",
    "Thought: find the manager's id by manager's name.\n",
    "Action: HRM get by name\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, 139, [start date], [end date]\n",
    "Thought: ask user the date of starting leaving (according the format Year-Month-Day)?\n",
    "Action: human\n",
    "Action Input: When do you want to start your leave? (I'm currently using Year-Month-Day format)\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb , 139, 2023-07-17, [end date]\n",
    "Thought: ask user the date of ending leaving (according the format Year-Month-Day)?\n",
    "Action: human\n",
    "Action Input: When do you want to end your leave? (I'm currently using Year-Month-Day format)\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb , 139, 2023-07-17, 2023-07-18\n",
    "Thought: I have all the details from the user, I will now submit the application.\n",
    "Action: HRM submit leave\n",
    "Observation: success\n",
    "Thought: The leave application was submitted successfully.\n",
    "Final Answer: The leave application was submitted successfully.'''\n",
    "\n",
    "example2 = '''Examples: \n",
    "\n",
    "Thought: find the user's id.\n",
    "Action: HRM get user info\n",
    "Action Input: None\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb, [manager's id], [start date], [end date]\n",
    "Thought: Ask the user for the manager's name.\n",
    "Action: human\n",
    "Action Input: What is the name of the manager who will approve your application?\n",
    "Observation: lý minh quân\n",
    "Thought: find the manager's id.\n",
    "Action: HRM get manager id\n",
    "Action Input: lý minh quân\n",
    "Observation: 139\n",
    "Thought: ask user the date of starting leaving (according the format Year-Month-Day)?\n",
    "Action: human\n",
    "Action Input: When do you want to start your leave? (I'm currently using Year-Month-Day format)\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb , 139, 2023-07-17, [end date]\n",
    "Thought: ask user the date of ending leaving (according the format Year-Month-Day)?\n",
    "Action: human\n",
    "Action Input: When do you want to end your leave? (I'm currently using Year-Month-Day format)\n",
    "Observation: 65255df1-d4c3-479b-a4b8-d63cb3db2beb , 139, 2023-07-17, 2023-07-18\n",
    "Thought: I have all the details from the user, I will now submit the application.\n",
    "Action: HRM submit leave\n",
    "Observation: success\n",
    "Thought: I now know the final answer\n",
    "Final Answer: The leave application was submitted successfully.\n",
    "Finished chain.\n",
    "\n",
    "'''\n",
    "\n",
    "suffix = \"\"\"Begin!\n",
    "\n",
    "Conversation history:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "suffix = '' + suffix\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"context\", \"agent_scratchpad\"],\n",
    ")\n",
    "\n",
    "history = ConversationBufferWindowMemory(k=3, memory_key=\"context\", human_prefix='User', ai_prefix='Assistant', return_messages=True)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm3, prompt=prompt)\n",
    "\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True, stop=[\"\\nObservation:\", \"<|im_end|>\", \"<|im_sep|>\"])\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools, \n",
    "    verbose=True,\n",
    "    handle_parsing_errors=\"If you have finished your task, end with Final Answer: <your output final output message>\",\n",
    "    memory=history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a6d3ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to ask the user for their manager's name and the start and end dates of their leave.\n",
      "Action: HRM get user info\n",
      "Action Input: None\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mUser info:\n",
      "id: 7cc99c43-1951-4bc1-a1c9-ca3487b1d6f3\n",
      "name: Bao Ho\n",
      "email: bao.ho@nois.vn\n",
      "fullName: HỒ NGUYỄN NGỌC BẢO\n",
      "jobTitle: Lập Trình Viên\n",
      "mobilePhone: \n",
      "birthday: 2002-04-30\n",
      "offDay: 0\n",
      "yearOffDay: 3\n",
      "maxDayOff: 12\n",
      "remainingOffDays: 12\n",
      "remainDayOffLastYear: 0\n",
      "offDayUseRamainDayOffLastYear: 0\n",
      "gender: 1\n",
      "personalEmail: honguyenngocbao@gmail.com\n",
      "avatar: \n",
      "acceptOfferDate: \n",
      "quitJobDate: \n",
      "bonusDayOff: 0\n",
      "managerId: 139\n",
      "managerFullName: LÝ MINH QUÂN\n",
      "departmentId: 0\n",
      "departmentName: \n",
      "groupUserId: \n",
      "groupUserName: \n",
      "hasLeft: \n",
      "identityCard: \n",
      "dateOfIssue: \n",
      "issuedBy: \n",
      "placeOfTemporaryResidence: \n",
      "placeOfResidence: \n",
      "relativeName: \n",
      "relationship: \n",
      "relativeMobilePhone: \n",
      "hasBankAccount: \n",
      "bankName: \n",
      "bankBranch: \n",
      "bankAccountNumber: \n",
      "birthPlace: \n",
      "isFirstLogin: \n",
      "roles: \n",
      "taxIdentificationNumber: \n",
      "education: \n",
      "jobId: \n",
      "jobName: \n",
      "levelId: \n",
      "levelName: \n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the user's id and can ask for their manager's name.\n",
      "Action: HRM get manager id\n",
      "Action Input: LÝ MINH QUÂN\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m139\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the manager's id and can ask for the start and end dates of the leave.\n",
      "Action: HRM submit leave\n",
      "Action Input: 7cc99c43-1951-4bc1-a1c9-ca3487b1d6f3, 139, 2023-07-20, 2023-07-25\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data 'Thursday 2023-07-13' does not match format '%Y-%m-%d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m history\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m----> 2\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43magent_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md like to submit a leave application.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\lib\\site-packages\\langchain\\chains\\base.py:445\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    441\u001b[0m         _output_key\n\u001b[0;32m    442\u001b[0m     ]\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    446\u001b[0m         _output_key\n\u001b[0;32m    447\u001b[0m     ]\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\lib\\site-packages\\langchain\\chains\\base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    242\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    244\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    245\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    247\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\lib\\site-packages\\langchain\\chains\\base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[0;32m    231\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    232\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    233\u001b[0m     inputs,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 237\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    240\u001b[0m     )\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    242\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\lib\\site-packages\\langchain\\agents\\agent.py:987\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m--> 987\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m    995\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m    996\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m    997\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\lib\\site-packages\\langchain\\agents\\agent.py:850\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    848\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m     observation \u001b[38;5;241m=\u001b[39m tool\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    851\u001b[0m         agent_action\u001b[38;5;241m.\u001b[39mtool_input,\n\u001b[0;32m    852\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    853\u001b[0m         color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[0;32m    854\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_run_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    858\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\lib\\site-packages\\langchain\\tools\\base.py:320\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    319\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[1;32m--> 320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28mstr\u001b[39m(observation), color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    324\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\lib\\site-packages\\langchain\\tools\\base.py:292\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[0;32m    291\u001b[0m     observation \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 292\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;241m*\u001b[39mtool_args, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    295\u001b[0m     )\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ToolException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_tool_error:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\lib\\site-packages\\langchain\\tools\\base.py:450\u001b[0m, in \u001b[0;36mTool._run\u001b[1;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m new_argument_supported \u001b[38;5;241m=\u001b[39m signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m    446\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    448\u001b[0m     )\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_argument_supported\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    451\u001b[0m )\n",
      "Cell \u001b[1;32mIn[12], line 105\u001b[0m, in \u001b[0;36msubmitLeaveApplication\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m lst[\u001b[38;5;241m2\u001b[39m]:\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsk the user when they want to start their leave. Infer the date based on the user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms answer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mstrptime(lst[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart date cannot be earlier than current date, ask the user for another date.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m lst[\u001b[38;5;241m3\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\lib\\_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    566\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\lib\\_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    347\u001b[0m found \u001b[38;5;241m=\u001b[39m format_regex\u001b[38;5;241m.\u001b[39mmatch(data_string)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n",
      "\u001b[1;31mValueError\u001b[0m: time data 'Thursday 2023-07-13' does not match format '%Y-%m-%d'"
     ]
    }
   ],
   "source": [
    "history.clear()\n",
    "answer = agent_chain.run(input=\"I'd like to submit a leave application.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b293b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"OK\",\"data\":\"success\"}\n",
      "{\"message\":\"OK\",\"data\":\"success\"}\n",
      "{\"message\":\"OK\",\"data\":\"success\"}\n"
     ]
    }
   ],
   "source": [
    "delAll(\"7cc99c43-1951-4bc1-a1c9-ca3487b1d6f3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57b48ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"OK\"}\n"
     ]
    }
   ],
   "source": [
    "new_user = {\n",
    "    \"name\": \"Bao Ho\",\n",
    "    \"email\": \"bao.ho@nois.vn\",\n",
    "    \"fullName\": \"HỒ NGUYỄN NGỌC BẢO\",\n",
    "    \"jobTitle\": \"Lập Trình Viên\",\n",
    "    \"birthday\": \"2002-04-30\",\n",
    "    \"gender\": 1,\n",
    "    \"personalEmail\": \"honguyenngocbao@gmail.com\",\n",
    "    \"managerId\": '139',\n",
    "    \"managerFullName\": \"LÝ MINH QUÂN\",\n",
    "    \"maxDayOff\": 12,\n",
    "    \"yearOffDay\": 3\n",
    "}\n",
    "\n",
    "reply = requests.post(url + 'api/User', json = new_user)\n",
    "print(reply.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc2e4097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"OK\",\"data\":{\"id\":\"7cc99c43-1951-4bc1-a1c9-ca3487b1d6f3\",\"name\":\"Bao Ho\",\"email\":\"bao.ho@nois.vn\",\"fullName\":\"HỒ NGUYỄN NGỌC BẢO\",\"jobTitle\":\"Lập Trình Viên\",\"mobilePhone\":\"\",\"birthday\":\"2002-04-30\",\"offDay\":0,\"yearOffDay\":3,\"maxDayOff\":12,\"remainDayOffLastYear\":0,\"offDayUseRamainDayOffLastYear\":0,\"gender\":1,\"personalEmail\":\"honguyenngocbao@gmail.com\",\"avatar\":\"\",\"acceptOfferDate\":\"\",\"quitJobDate\":\"\",\"bonusDayOff\":0,\"managerId\":\"139\",\"managerFullName\":\"LÝ MINH QUÂN\",\"departmentId\":0,\"departmentName\":\"\",\"groupUserId\":\"\",\"groupUserName\":\"\",\"hasLeft\":\"\",\"identityCard\":\"\",\"dateOfIssue\":\"\",\"issuedBy\":\"\",\"placeOfTemporaryResidence\":\"\",\"placeOfResidence\":\"\",\"relativeName\":\"\",\"relationship\":\"\",\"relativeMobilePhone\":\"\",\"hasBankAccount\":\"\",\"bankName\":\"\",\"bankBranch\":\"\",\"bankAccountNumber\":\"\",\"birthPlace\":\"\",\"isFirstLogin\":\"\",\"roles\":\"\",\"taxIdentificationNumber\":\"\",\"education\":\"\",\"jobId\":\"\",\"jobName\":\"\",\"levelId\":\"\",\"levelName\":\"\"}}\n"
     ]
    }
   ],
   "source": [
    "print(requests.get(url + 'api/User/me?email=bao.ho@nois.vn').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849dbddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(requests.delete(url + 'api/User/d5415e70-eb99-4536-a649-777efd829e07').text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
